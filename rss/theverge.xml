<feed xml:lang="en" xmlns="http://www.w3.org/2005/Atom"><title>边缘 - 人工智能</title><icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon><updated> 2023-08-17T16:09:42-04:00</updated><id> https://www.theverge.com/rss/ai-artificial-intelligence/index.xml </id><link href="https://www.theverge.com/ai-artificial-intelligence" rel="alternate" type="text/html"/><entry><published> 2023-08-17T16:09:42-04:00</published><updated> 2023-08-17T16:09:42-04:00</updated><title>微软的人工智能推荐渥太华食品银行作为旅游目的地</title><content type="html">&lt;figure>; &lt;img alt=&quot;绿色背景上的 Microsoft 字标插图&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/sfvLvQHqqW3rbEQojyjcjGahFUg=/0x0:2040x1360/1310x873/cdn.vox-cdn. com/uploads/chorus_image/image/72554358/STK095_Microsoft_03.0.jpg&quot; />; &lt;figcaption>;插图：The Verge&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;39N5wO&quot;>;Microsoft 已发布 &lt;a href=&quot; https://www.msn.com/en-gb/lifestyle/travel/headed-to-ottawa-here-s-what-you-shouldn-t-miss/ar-AA1faajY&quot;>;AI 生成的有关渥太华的旅行文章，加拿大&lt;/a>;，显着推荐游客参观渥太华食品银行，&lt;a href=&quot;https://twitter.com/parismarx/status/1692233111260582161&quot;>;巴黎马克思发现&lt;/a>;。食品银行是榜单上排名第三的推荐，位于国家战争纪念馆后面，上面是观看渥太华参议员曲棍球比赛的地方。&lt;/p>; &lt;p id=&quot;OfADo8&quot;>;微软解雇了 Microsoft News 和 MSN 的记者2020 年&lt;a href=&quot;https://www.theverge.com/2020/5/30/21275524/microsoft-news-msn-layoffs-artificial-intelligence-ai-replacements&quot;>;用人工智能取代它们&lt;/一个>;。微软没有立即回应置评请求。&lt;/p>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot;微软有关渥太华旅游目的地的文章的屏幕截图。&quot; data-mask-text=&quot;false&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/wrp6umE2tRlrpsyz0BPmAukIt5Q=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file /24857247/Screenshot_2023_08_17_at_12.47.06_PM.png&quot;>; &lt;cite>;Jay Peters / The Verge 的屏幕截图&lt;/cite>; &lt;/figure>; &lt;p id=&quot;shmXHb&quot;>;这里是&lt;a href=&quot;https://www. ottawafoodbank.ca/donate/&quot;>;渥太华食品银行网站&lt;/a>;（如果您想捐赠）——由于自 2019 年以来需求激增 85%，该银行最近搬到了新地点。尽管鼓励支持，但首席执行官 Rachael威尔逊 &lt;a href=&quot;https://www.cbc.ca/news/canada/ottawa/ottawa-food-bank-bigger-location-1.6861145&quot;>;6 月份告诉 CBC&lt;/a>;，“我们的希望是有一天关上我们的大门……减少需要食品银行的人数。”&lt;/p>; &lt;p id=&quot;kSff9L&quot;>;文章中的每个部分都带有模糊的“Microsoft Travel”字样，都有一个简要文字描述您对目的地的期望。对于食品银行，微软的摘要中包含了一个令人震惊的糟糕声明，考虑到它所谈论的地方的背景：“来到我们这里的人有工作和家庭需要养活，还有需要支付的费用。生活已经够困难的了。考虑空腹进入。”&lt;/p>; &lt;p id=&quot;8Nw33G&quot;>;“不用说，这不是我们会发布或希望包含的消息或‘故事’类型， ” 渥太华食品银行通讯经理 Samantha Koziara 在给 &lt;em>;The Verge&lt;/em>; 的一份声明中说道。 “‘空腹’这句话显然是不敏感的，并且没有经过（人类）编辑。据我所知，我们以前从未见过这样的事情 - 但随着人工智能变得越来越流行，我毫不怀疑在诸如此类的列表中会出现越来越多的不准确/不适当的引用。这凸显了研究人员、作家和编辑……对人类多样性的重要性。”&lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;jQZjBR&quot;>;&lt;div data-anthem-component=&quot;readmore&quot; data-anthem-component-data=&#39;{&quot;stories&quot;:[{&quot;title&quot;:&quot;Bing、Bard 和 ChatGPT：人工智能如何重写互联网&quot;,&quot;url&quot;:&quot; https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai&quot;}]}&#39;>;&lt;/div>;&lt;/aside>;&lt;/div>; &lt;p id=&quot; O2kRDs&quot;>;“每天，我们的算法都会梳理合作伙伴发送的数十万条内容，”微软在“关于我们”页面中写道 &lt;a href=&quot;https://www.msn.com/en-us /news/us/about-us/ar-BBN0NAK&quot;>;其 Microsoft Start 计划&lt;/a>;。 “我们对其进行处理以了解新鲜度、类别、主题类型、意见内容和潜在受欢迎程度等维度，并根据用户偏好进行发布。这与人工监督相结合，以确保我们展示的内容符合我们的价值观，并且关键信息在我们的体验中占据显着位置。”&lt;/p>; &lt;p id=&quot;C5xzsO&quot;>;最近，其他出版商已转向人工智能来补充或取代人类的工作，但往往效果不佳。 Gizmodo 的一篇人工智能撰写的文章未能&lt;a href=&quot;https://www.theverge.com/2023/7/8/23788162/gizmodo-go-media-ai- generated-articles -star-wars&quot;>;按时间顺序正确列出&lt;em>;星球大战&lt;/em>;电影&lt;/a>;。 &lt;em>;CNET&lt;/em>;发布了&lt;a href=&quot;https://www.theverge.com/2023/1/25/23571082/cnet-ai-writing-stories-errors- Corrections-red-ventures&quot;>;更正关于数十个人工智能编写的故事&lt;/a>;。 &lt;em>;BuzzFeed&lt;/em>; 与 Microsoft 一样，&lt;a href=&quot;https://www.theverge.com/2023/3/30/23663206/buzzfeed-ai-travel-guides-buzzy&quot;>;已经使用 AI撰写旅游指南&lt;/a>;。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/17/23836287/microsoft-ai-recommends-ottawa-food-bank-tourist-destination" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/17/23836287/microsoft-ai-recommends-ottawa-food-bank-tourist-destination</id><author><name>杰·彼得斯</name></author></entry><entry><published>2023-08-16T14:05:45-04:00</published><updated> 2023-08-16T14:05:45-04:00</updated><title>美联社为记者制定人工智能指南</title><content type="html">&lt;图>; &lt;img alt=&quot;美联社徽标&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/K1h2wNa-UY0OUvKXIzyWfaSS734=/0x0:640x427/1310x873/cdn.vox-cdn.com/uploads/ chorus_image/image/72550496/AP_logo_640.0.jpg&quot; />; &lt;figcaption>;图片：AP&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;aZBdgJ&quot;>;&lt;em>;美联社&lt;/em>;发布了有关生成的指南人工智能向其记者提供帮助，因为它和其他新闻机构正在寻找在新闻采集中使用该技术的方法。 &lt;/p>; &lt;p id=&quot;FUrBxb&quot;>;&lt;em>;AP&lt;/em>; 标准和包容性副总裁 Amanda Barrett &lt;a href=&quot;https://blog.ap.org/standards-around-generative-ai ”>;在一篇博文中&lt;/a>;表示，该出版物并不认为人工智能“以任何方式取代记者”，而是为记者和编辑制定了如何使用它的指南。 &lt;/p>; &lt;p id=&quot;jQOsi1&quot;>;&lt;em>;美联社&lt;/em>;的记者可以尝试使用 ChatGPT，但请谨慎行事，不要使用该工具创建可发布的内容。生成式人工智能平台的任何结果“都应被视为未经审查的源材料”，并遵守美联社现有的采购标准。该出版物表示，它不会允许人工智能改变照片、视频或音频，也不会使用人工智能生成的图像，除非它是新闻报道的主题。在这种情况下，美联社表示将在标题中标记人工智能生成的照片。 &lt;/p>; &lt;p id=&quot;3XzOIS&quot;>;作家不能将机密信息放入人工智能工具中，并应确保他们使用的其他来源“不含人工智能生成的内容”。 &lt;em>;美联社&lt;/em>;工作人员被要求避免意外使用为传播错误信息而创建的人工智能内容，并应验证他们使用的内容的准确性。 &lt;/p>; &lt;p id=&quot;EaYAuS&quot;>;记者密切关注&lt;em>;美联社&lt;/em>;围绕标准的举措，因为大多数新闻行业都使用或至少修改&lt;em>;美联社样式手册&lt;/em>; >; 撰写像您现在正在阅读的文章一样的文章。有些人甚至拥有几本（旧的）《Stylebook》实体版，因为他们是新闻迷。它的指导可能会对有关记者使用人工智能的激烈争论产生影响。 &lt;/p>; &lt;p id=&quot;7LhLnj&quot;>;即使&lt;em>;美联社&lt;/em>;为其员工设定了这些标准，该出版物&lt;a href=&quot;https://www.theverge.com/2023/7/ 13/23793810/openai-associate-press-ai-models&quot;>;与 ChatGPT 制造商 OpenAI 签署协议&lt;/a>;，使用其新闻报道来训练生成式 AI 模型。 &lt;em>;美联社&lt;/em>;还使用自动化工具来快速撰写有关财务报告和小型体育联盟的文章；它已加入其他 &lt;a href=&quot;https://www.theverge.com/2023/1/26/23572834/buzzfeed-using-ai-tools-personalize-generate-content-openai&quot;>;组织，例如 BuzzFeed &lt;/em>;&lt;/a>;&lt;em>; &lt;/em>;在其工作流程中使用人工智能。它还与其他新闻公司和团体一起&lt;a href=&quot;https://www.theverge.com/2023/8/10/23827316/news-transparency-copyright-generative-ai&quot;>;签署了一封公开信&lt;/a >; 敦促数据透明以训练生成式人工智能模型。 &lt;/p>; &lt;p id=&quot;Q3AVuP&quot;>;&lt;em>;美联社&lt;/em>;的指南遵循&lt;a href=&quot;https://www.theverge.com/2023/8/14/23831109/the -new-york-times-ai-web-scraping-rules-terms-of-service&quot;>;&lt;em>;《纽约时报》&lt;/em>;限制使用其数据来训练人工智能模型并撤回与人工智能公司围绕训练数据进行谈判的联盟。 &lt;/p>; </content><link href="https://www.theverge.com/2023/8/16/23834586/associated-press-ai-guidelines-journalists-openai" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/16/23834586/ Associated-press-ai-guidelines-journalists-openai</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-16T13:38:02-04:00</published><updated> 2023-08-16T13:38:02-04:00</updated><title> OpenAI 收购了《我的世界》克隆版的制造商</title><content type="html">&lt;figure>; &lt;img alt=&quot;Biomes 的屏幕截图。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/zG5IYIDmFjPBOaMFVx_-joyCOFc=/200x0:2360x1440/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72550376/Biomes___Open_Source_Sandbox_MMO__Official_Trailer ______生物群落____开放源_沙盒_MMO__官方_预告片__2023_8_16_101820.905_1440p_streamshot.0。 png&quot; />; &lt;figcaption>;图片：Global Illumination&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;joybuh&quot;>;OpenAI 表示已收购 Global Illumination，这是一家总部位于纽约的小公司，自称是“数字产品”公司。”&lt;/p>; &lt;p id=&quot;pBBp6G&quot;>;在&lt;a href=&quot;https://openai.com/blog/openai-acquires-global-illustration&quot;>;其公告&lt;/a>;中，OpenAI 并没有“没有透露收购条款，但表示 Global Illumination 的“整个团队”已加入该公司，致力于开发其“核心产品”，包括 ChatGPT。除此之外，OpenAI 没有具体说明全局照明团队将在公司做什么。 OpenAI 没有立即回复置评请求。&lt;/p>; &lt;p id=&quot;Yg0atT&quot;>;“Global Illumination 是一家一直利用人工智能构建创意工具、基础设施和数字体验的公司，”OpenAI 在这个通告。 “该团队之前曾在 Instagram 和 Facebook 早期设计和构建产品，并且还在 YouTube、Google、Pixar、Riot Games 和其他知名公司做出了重大贡献。” &lt;/p>; &lt;p id=&quot;2U3Lv3&quot;>;Global Illumination 的网站&lt;a href=&quot;https://ill.inc/&quot;>;相当稀疏&lt;/a>;。它有公司的简短描述，列出了八名员工，并有一个指向&lt;a href=&quot;https://www.biomes.gg/&quot;>;一款名为&lt;em>;Biomes&lt;/em>;&lt;/a>;的游戏的链接，它被描述为“为网络构建的开源沙盒 MMORPG”。 （从图形上看，该游戏与&lt;em>;我的世界&lt;/em>;非常相似。）&lt;/p>; </content><link href="https://www.theverge.com/2023/8/16/23834645/openai-global-illumination-acquisition-minecraft-clone-chatgpt" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/16/23834645/openai-global-illustration-acquisition-minecraft-clone-chatgpt</id><author><name>杰·彼得斯</name></author></entry><entry><published>2023-08-15T17:01:21-04:00</published><updated> 2023-08-15T17:01:21-04:00</updated><title> Bing、Bard 和 ChatGPT：人工智能如何重写互联网</title><content type="html">&lt;figure>; &lt;img alt=&quot;用额外的手指在键盘上打字的手。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/Mt5QeFarbefgZzBlc5YUaZ6SLus=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72006379/AI_Hands_A_Bernis_02.0.jpg&quot;/>; &lt;figcaption>;Álvaro Bernis / The Verge&lt;/figcaption>; &lt;/figure>; &lt;p>;由于人工智能聊天机器人的进步，我们使用互联网的方式正在迅速改变，这些机器人可以查找信息并将其作为简单的对话重新传递。&lt;/ p>; &lt;p id=&quot;doouw2&quot;>;包括微软在内的大玩家，及其 &lt;a href=&quot;https://www.theverge.com/2023/2/7/23587454/microsoft-bing-edge-chatgpt-ai &quot;>;Bing AI&lt;/a>;（&lt;em>;和&lt;/em>;&lt;a href=&quot;https://www.theverge.com/2023/3/16/23642833/microsoft-365-ai-copilot-word- Outlook-teams&quot;>;Copilot&lt;/a>;），Google，与 &lt;a href=&quot;https://www.theverge.com/2023/3/21/23649794/google-chatgpt-rival-bard-ai-chatbot- access-hands-on&quot;>;Bard&lt;/a>; 和 OpenAI，具有 &lt;a href=&quot;https://www.theverge.com/2023/3/15/23640047/openai-gpt-4-differences-capabilties- function&quot;>;ChatGPT-4&lt;/a>; 正在使以前仅限于测试实验室的人工智能聊天机器人技术更容易为公众所使用。 &lt;/p>; &lt;p id=&quot;IkyUrm&quot;>;这些大型语言模型 (LLM) 程序如何工作？ OpenAI 的 &lt;a href=&quot;https://www.theverge.com/22734662/ai-language-artificial-intelligence-future-models-gpt-3-limitations-bias&quot;>;GPT-3 告诉我们&lt;/a>;，人工智能使用“一系列类似自动完成的程序来学习语言”，并且这些程序分析“语言的统计特性”，以“根据您之前输入的单词做出有根据的猜测”。 &lt;/p>; &lt;p id=&quot;zFwDLC&quot;>;或者，&lt;a href=&quot;https://www.theverge.com/2023/1/5/23540291/chatgpt-ai-writing-tool-banned-writing-academic -icml-paper&quot;>;用人类 James Vincent&lt;/a>; 的话说：“这些人工智能工具是巨大的自动完成系统，经过训练可以预测任何给定句子中下一个单词后面的单词。因此，他们没有硬编码的“事实”数据库可供利用——只有编写听起来合理的陈述的能力。这意味着他们倾向于将虚假信息当作事实，因为给定的句子听起来是否可信并不能保证其真实性。”&lt;/p>; &lt;p id=&quot;xAXBTH&quot;>;但是人工智能领域还有很多其他方面，正在发挥作用 - 并且有&lt;a href=&quot;https://www.theverge.com/2023/2/9/23592647/ai-search-bing-bard-chatgpt-microsoft-google-problems-challenges&quot;>;将会出现问题&lt;/a>; - 但您一定可以在 &lt;em>;The Verge&lt;/em>; 上看到这一切。&lt;/p>; </content><link href="https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai" rel="alternate" type="text/html"/><id> https://www.theverge.com/23610427/chatbots-chatgpt-new-bing-google-bard-conversational-ai</id><author><name>杰·彼得斯</name><name>亚历克斯·希思</name><name>佐藤米亚</name><name>艾玛·罗斯</name><name>艾米莉亚·大卫</name><name>韦斯·戴维斯</name><name>大卫·皮尔斯</name><name>理查德·劳勒</name></author></entry><entry><published>2023-08-15T16:57:27-04:00</published><updated> 2023-08-15T16:57:27-04:00</updated><title>爱荷华州的一个学区正在使用 ChatGPT 来决定禁止哪些书籍</title><content type="html">&lt;图>; &lt;img alt=&quot;ChatGPT 徽标&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/xL1vgIA0LXhLQqrs5VpI8-eo_mE=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image /image/72547714/STK149_AI_02.0.jpg&quot; />; &lt;figcaption>;插图：The Verge&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;IzeWoT&quot;>;爱荷华州梅森城社区学区正在从学校图书馆撤回 19 本书，这些图书管理员被发现包含“性行为的描述或描述”，以遵守共和党支持的州法律。是否应该禁止这些书籍的关键仲裁者：ChatGPT。&lt;/p>; &lt;p id=&quot;vA0yd8&quot;>;该学区在决策中使用人工智能软件的消息首先由&lt;em>;梅森城环球公报&lt; /em>; &lt;a href=&quot;https://www.thegazette.com/k/19-books-pulled-from-mason-city-school-libraries/&quot;>;上周&lt;/a>;，但事实并非如此明确使用了什么工具——或者官员到底是如何做的——直到&lt;em>;大众科学&lt;/em>;&lt;a href=&quot;https://www.popsci.com/technology/iowa-chatgpt-book-ban/ &quot;>;报告&lt;/a>;使用了 ChatGPT。禁书包括卡勒德·胡赛尼 (Khaled Hosseini) 的《追风筝的人》、玛格丽特·阿特伍德 (Margaret Atwood) 的《使女的故事》和玛雅·安吉卢 (Maya Angelou) 的《我知道笼中鸟为何歌唱》 .&lt;/p>; &lt;p id=&quot;JrDxxd&quot;>;根据&lt;em>;大众科学&lt;/em>;的报告，管理员输入了查询：“[书]包含性行为的描述或描绘吗？”将每本经常受到质疑的书籍添加到 ChatGPT 中。&lt;/p>; &lt;p id=&quot;0aEQUJ&quot;>;“如果答案是肯定的，该书将从流通中删除并存储，”Bridgette Exman，课程和教学助理总监梅森城告诉《大众科学》。 &lt;/em>;&lt;/p>; &lt;p id=&quot;FxwB9b&quot;>;Exman 告诉媒体，该学区不可能阅读列表中的每本潜在书籍来寻找可以&lt;a href=&quot;https:// www.cnn.com/2023/05/27/politics/iowa-law-gender-identity-book-ban/index.html&quot;>;违反了五月颁布的全面州法律&lt;/a>;。即使新学年即将到来，许多教育工作者和学区表示，州&lt;a href=&quot;https://www.kcci.com/article/iowa-state-board-of-education-meets-about-book-限制/44727617&quot;>;尚未就如何实施课程变更提供明确的指导方针&lt;/a>;。 &lt;/p>; &lt;p id=&quot;clkHnm&quot;>;梅森市管理人员表示，他们有教授某些书籍的经验，并且在使用 ChatGPT 检索答案后，由图书管理员“管理[列表]”。但根据用户提示和查询软件的方式，该工具生成的答案有时会相互矛盾。当 The Verge 将梅森市学区禁止的所有 19 本书的列表输入 ChatGPT 并询问它们是否包含露骨或性场景时，该软件表明有几本不包含该内容。 &lt;/p>; &lt;p id=&quot;HO9yaq&quot;>;Exman 告诉 &lt;em>;The Verge&lt;/em>;，该学区开始使用新闻文章和维基百科等来源来收集常见禁书的初始列表，然后将其削减到大约 50 种图书馆馆藏中存在的标题。 Exman 随后使用 ChatGPT 对这 50 本书中的每一本书进行了一次测试。尽管埃克斯曼还没有收到其他管理员使用这些方法解决该问题的消息，但其他学区已经伸出援手。 &lt;/p>; &lt;p id=&quot;xLtDLb&quot;>;“我们的目的是展示遵守法律的诚意，而不是重新安排我们应该用来准备迎接老师和学生的时间和精力。回来再读一个学年，”Exman 在一封电子邮件中告诉 The Verge。 “我们的目标是找到一个有效的流程来开始新的一年，然后依靠我们长期的流程，允许家长要求学区重新考虑。当前在列表中的书籍可以重新考虑，就像不在列表中的书籍可以重新考虑一样。”&lt;/p>; &lt;p id=&quot;p1toYN&quot;>;&lt;/p>; &lt;p id=&quot;Ghtpbs&quot;>;&lt; /p>; </content><link href="https://www.theverge.com/2023/8/15/23833167/iowa-book-ban-chatgpt-mason-city-community-school-district-removal" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/15/23833167/iowa-book-ban-chatgpt-mason-city-community-school-district-removal</id><author><name>佐藤米娅</name></author></entry><entry><published>2023-08-15T16:50:15-04:00</published><updated> 2023-08-15T16:50:15-04:00</updated><title> OpenAI 希望 GPT-4 解决内容审核困境</title><content type="html">&lt;figure>; &lt;img alt=&quot;OpenAI 徽标的演绎，看起来像一个风格化的漩涡。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/-u5SjvzTswLoxTIwtv2woZumWo4=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72547677/STK149_AI_03.0.jpg&quot;/ >; &lt;figcaption>;插图：The Verge&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;0VWQUA&quot;>;OpenAI 坚信其技术可以帮助解决技术最困难的问题之一：&lt;a href=&quot;https://www. techdirt.com/2019/11/20/masnicks-impossibility-theorem-content-moderation-scale-is-impossible-to-do-well/&quot;>;大规模内容审核&lt;/a>;。 OpenAI 声称，GPT-4 可以取代数以万计的人工审核员，同时几乎同样准确且更加一致。如果这是真的，&lt;a href=&quot;https://www.theverge.com/2019/12/16/21021005/google-youtube-moderators-ptsd-accenture-violent-disturbing-content-interviews-video&quot;>;大多数科技领域有毒且费脑力的任务可以外包给机器。&lt;/p>; &lt;p id=&quot;5vqN2Y&quot;>;&lt;a href=&quot;https://openai.com/blog/using-gpt-4- for-content-moderation&quot;>;在一篇博文&lt;/a>;中，OpenAI 声称它已经在使用 GPT-4 来开发和完善自己的内容政策、标记内容和做出决策。 OpenAI 安全系统负责人 Lilian Weng &lt;a href=&quot;https://www.semafor.com/article/08/15/ 2023/can-chatgpt-become-a-content-moderator#room-for-disagreement&quot;>;告诉&lt;em>;Semafor&lt;/em>;&lt;/a>;。 “这对于我们如何使用人工智能以一种对社会有益的方式解决现实世界问题来说是一个非常好的进步。”&lt;/p>; &lt;p id=&quot;fRNwMd&quot;>;与传统的内容方法相比，OpenAI 看到了三个主要好处适度。首先，它声称人们对政策的解释不同，而机器的判断是一致的。这些指导方针可以像一本书一样长，并且不断变化。虽然人类需要大量的训练来学习和适应，但 OpenAI 认为大型语言模型可以立即实施新策略。&lt;/p>; &lt;p id=&quot;UOSGsE&quot;>;其次，据称 GPT-4 可以帮助在数小时内制定新策略。起草、标记、收集反馈和完善的过程通常需要几周或几个月的时间。第三，OpenAI 提到了持续接触有害内容（例如虐待儿童或酷刑视频）的工人的福祉。&lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt; side id=&quot;6lXMYM&quot;>;&lt;q>;OpenAI 可能有助于解决其自身技术加剧的问题&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;5LC9tL&quot;>;经过近二十年的现代社交媒体即使在线社区发展多年，内容审核仍然是在线平台最困难的挑战之一。 Meta、谷歌和 TikTok 都依赖大量的版主，他们必须浏览可怕且经常造成创伤的内容。其中大多数位于工资较低的发展中国家，&lt;a href=&quot;https://www.theverge.com/interface/2019/11/1/20941952/cognizant-content-moderation-restructuring-facebook-twitter-google &quot;>;为外包公司工作&lt;/a>;，并与心理健康作斗争，因为他们只接受最低限度的心理健康护理。&lt;/p>; &lt;p id=&quot;wutblH&quot;>;然而，OpenAI 本身 &lt;a href=&quot;https ://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots&quot;>;严重依赖 clickworkers 和人工&lt;/a>;。成千上万的人（其中许多人来自肯尼亚等非洲国家）对内容进行注释和标签。这些短信可能会令人不安，工作压力很大，&lt;a href=&quot;https://time.com/6247678/openai-chatgpt-kenya-workers/&quot;>;而且工资很低&lt;/a>;。&lt;/p>; &lt;p id=&quot;xxFlLi&quot;>;虽然 OpenAI 宣称其方法是新颖且革命性的，但人工智能已经被使用&lt;a href=&quot;https://www.theverge.com/2020/11/13/21562596/facebook-ai-moderation &quot;>;多年来内容审核&lt;/a>;。马克·扎克伯格关于完美自动化系统的愿景尚未完全实现，但 Meta 使用算法来控制绝大多数有害和非法内容。 YouTube 和 TikTok 等平台依赖于类似的系统，因此 OpenAI 的技术可能会吸引那些没有资源开发自己的技术的小公司。&lt;/p>; &lt;p id=&quot;QVNV9z&quot;>;每个平台都公开承认完美的内容大规模的节制是不可能的。人类和机器都会犯错误，虽然百分比可能很低，但仍然有数以百万计的有害帖子被漏掉，还有同样多的无害内容被隐藏或删除。&lt;/p>; &lt;p id=&quot;4g4Uv8&quot;>;特别是，误导性、错误性和攻击性内容（不一定是非法的）的灰色区域给自动化系统带来了巨大的挑战。即使是人类专家也很难给这些帖子贴上标签，而机器也经常出错。这同样适用于&lt;a href=&quot;https://www.theverge.com/2022/9/15/23353593/meta-facebook-oversight-board-decisions-automated-image-takedowns-extremist的讽刺或图像和视频-groups&quot;>;记录犯罪或警察暴行&lt;/a>;。&lt;/p>; &lt;p id=&quot;xw7ECC&quot;>;最终，OpenAI 可能有助于解决其自身技术加剧的问题。 ChatGPT 等生成式人工智能或该公司的图像创建者 DALL-E 使得大规模创建错误信息并在社交媒体上传播变得更加容易。尽管 OpenAI 承诺让 ChatGPT 更加真实，&lt;a href=&quot;https://www.theverge.com/2023/8/15/23825056/chatgpt-and-bard-still-willingly-spit-out-lies&quot;>; GPT-4 仍然愿意制造&lt;/a>;与新闻相关的虚假信息和错误信息。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/15/23833406/openai-gpt-4-content-moderation-ai-meta" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/15/23833406/openai-gpt-4-content-moderation-ai-meta</id><author><name>西蒙·赫茨</name></author></entry><entry><published>2023-08-15T12:57:54-04:00</published><updated> 2023-08-15T12:57:54-04:00</updated><title> Google Photos 添加生成人工智能来帮助命名您的照片集</title><content type="html">&lt;figure>; &lt;img alt=&quot;Google 相册应用程序的风格化插图，底部有照片、回忆、图库和搜索按钮&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/2rIjBRsh2l0HKLtpb8yVmc7EFLk=/0x0 :1550x1033/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72546821/Blog_Hero.0.jpeg&quot; />; &lt;figcaption>;&lt;em>;分享按钮消失了，为回忆腾出了空间。&lt;/em>; |图片：Google&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;Dk4Bf9&quot;>;Google 正在添加&lt;a href=&quot;https://blog.google/products/photos/google-photos-memories-view/&quot;>;a照片应用程序中新增“回忆”选项卡&lt;/a>;，为自动生成的图片集创建专用位置。该公司正在添加新的生成人工智能标题功能，也可以帮助您命名您的照片集。&lt;/p>; &lt;p id=&quot;LdfZDA&quot;>;这些 Google 生成的集合多年来一直显示在照片应用的顶部，但他们现在在应用程序底部有一个专用按钮。记忆的默认标题通常是使用图像 GPS 元数据的基于位置的名称。新的人工智能标题功能有助于以更多的乐趣和细节来总结类似 Instagram Stories 的风格演示。&lt;/p>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot; &quot; data-mask-text=&quot;假”src =“https://cdn.vox-cdn.com/thumbor/d6a1MoN6hjbuB8nXI_4e0BCwhWg =/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24851860/GenAI_Tidling.gif” >; &lt;cite>;GIF：Google&lt;/cite>; &lt;figcaption>;&lt;em>;新的生成式 AI 标题制作器。&lt;/em>;&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;hiShxv&quot;>;查看记忆集合时，您可以选择一个新的“帮助我标题”按钮，该按钮使用生成式人工智能根据图像内容来命名。如果初始输出不是您正在寻找的内容，您可以添加一个“提示”，这实际上是提示机器人将标题转向您正在寻找的方向。&lt;/p>; &lt;p id= &quot;Vzc72b&quot;>;新的回忆视图今天在美国推出，并将在“未来几个月”在全球范围内推出。后来，谷歌计划为回忆提供视频导出选项，以便可以通过消息传递和社交媒体平台轻松共享它们。 Apple 的照片应用程序已允许将其生成的“For You”和自定义幻灯片输出到视频以进行共享。&lt;/p>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot; &quot; data-mask-text=&quot;false&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/ktdjc-99CWJ94E2NPFuIghjoN1Q=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24851927/Memory_sharing_as_video_2.gif&quot; >; &lt;cite>;GIF：Google&lt;/cite>; &lt;figcaption>;&lt;em>;很快，您就可以将类似故事的幻灯片以视频形式分享到 WhatsApp 等消息应用程序。&lt;/em>;&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;AB7XLt&quot;>;如果工作正常，从 Google、Apple、Facebook 和其他公司生成的照片记忆可以让您从家庭度假跳到一场精彩的音乐会，让您渴望与亲人留下更多回忆。其他时候，它可以不加区别地选择&lt;a href=&quot;https://www.theverge.com/2015/6/4/8729943/laughing-and-crying-my-way-through-the-new-google-的照片照片&quot;>;没有意义&lt;/a>;，它可以唤起你生活中过去的时刻&lt;a href=&quot;https://www.wired.com/story/weddings-social-media-apps-photos -memories-miscarriage-problem/&quot;>;你不想重温&lt;/a>;。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/15/23832708/google-photos-memories-ai-generated-titles" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/15/23832708/google-photos-memories-ai- generated-titles</id><author><name>奥马尔·沙基尔</name></author></entry><entry><published>2023-08-15T12:38:55-04:00</published><updated> 2023-08-15T12:38:55-04:00</updated><title> Google Chrome 将使用内置的生成人工智能为您总结整篇文章</title><content type="html">&lt;figure>; &lt;img alt=&quot;明亮和深红色背景上的 Chrome 徽标插图。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/HjnuK8iDh5T1ftClkE-JYA3Oy-E=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72546709/STK114_Google_Chrome_01.0。 jpg&quot; />; &lt;figcaption>;图片：The Verge&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;7E4Jh5&quot;>;Google 的人工智能驱动的搜索生成体验 (SGE) 正在获得一项重要的新功能：它将能够总结根据&lt;a href=&quot;https://blog.google/products/search/google-search-generative-ai-learning-features/&quot;>;一篇 Google 博文&lt;/a>;，您在网络上阅读的文章。 SGE 已经可以为您汇总搜索结果，这样您就不必永远滚动来找到您要查找的内容，而这项新功能旨在进一步帮助您在实际单击链接后找到答案。 &lt;/p>; &lt;p id=&quot;0dykhU&quot;>;您可能不会立即看到此功能，Google 将其称为“浏览时的 SGE”。 &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>; &lt;aside id=&quot;Ox6iyo&quot;>;&lt;div data-anthem-component=&quot;readmore&quot; data-anthem-component-data=&#39;{ &quot;stories&quot;:[{&quot;title&quot;:&quot;Bing、Bard 和 ChatGPT：人工智能如何重写互联网&quot;,&quot;url&quot;:&quot;https://www.theverge.com/23610427/chatbots-chatgpt-new-bing -google-bard-conversational-ai&quot;}]}&#39;>;&lt;/div>;&lt;/aside>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot; &quot; data-mask-text=&quot;false&quot; src=&quot; https://cdn.vox-cdn.com/thumbor/No5-IEPpIpG9iXyiuCSl2qVzM1I=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24852120/google_chrome_sge.gif&quot;>; &lt;引用>;图片：Google&lt;/cite>; &lt;/figure>; &lt;/div>; &lt;p id=&quot;NRIJuT&quot;>;Google 表示，这是一项新功能，将于周二作为“早期实验”在 &lt;a href=&quot;https: //www.theverge.com/2023/5/10/237186​​82/google-labs-ai-search-workspace-tests-io&quot;>;其选择加入搜索实验室计划&lt;/a>;。 （如果您已经选择加入 SGE，您将可以访问它，但如果您还没有选择加入该功能，您可以自行选择加入该功能。）它将首先在 Android 和 iOS 上的 Google 应用程序中提供，并且该公司将“在未来几天”将其引入桌面版 Chrome 浏览器。&lt;/p>; &lt;p id=&quot;B22pTY&quot;>;如果您确实可以访问移动设备上的 Google 应用程序，Google 将调出一组 AI - 点击屏幕底部的图标后，从文章中生成“要点”。该功能旨在“仅适用于网络上向公众免费提供的文章”；谷歌表示，它不会与出版商标记为付费墙的网站合作。 &lt;/p>; &lt;p id=&quot;RQWf9S&quot;>;Google 还对 SGE 进行了一些其他改进。在 SGE 的有关科学、经济和历史等主题的搜索查询结果中，谷歌表示，您将能够将鼠标悬停在某些单词上以获得有关某个主题的定义或图表。 Google 还让人们更容易理解 SGE 的编码信息摘要。&lt;/p>; &lt;p id=&quot;6U2aK2&quot;>;Google 在 5 月份的 Google I/O 大会上宣布了 SGE，&lt;a href=&quot;https://www.theverge. com/2023/8/2/23817107/google-ai-search-generative-experience-videos-links&quot;>;此后几个月一直在改进&lt;/a>;。 &lt;a href=&quot;https://www.theverge.com/23746083/google-ai-search-generative-experience-slow&quot;>;我不喜欢它&lt;/a>;，但 Google 对其进展感到满意。在该公司的&lt;a href=&quot;https://abc.xyz/2023-q2-earnings-call/&quot;>;最新财报电话会议&lt;/a>;中，首席执行官桑达尔·皮查伊 (Sundar Pichai) 表示，用户反馈“到目前为止非常积极”，并且“随着时间的推移，这将成为搜索的工作方式。”&lt;/p>; </content><link href="https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge</id><author><name>杰·彼得斯</name></author></entry><entry><published>2023-08-15T09:40:16-04:00</published><updated> 2023-08-15T09:40:16-04:00</updated><title> Kneron今年将推出AI芯片</title><content type="html">&lt;图>; &lt;img alt=&quot;Kneron AI芯片&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/Whp6ZP8DYEvDKMdnhSiIxMPschA=/100x0:1180x720/1310x873/cdn.vox-cdn.com/uploads/chorus_image/ image/72545968/Kneron_KL730.0.jpg&quot; />; &lt;figcaption>;&lt;em>;Kneron KL730。&lt;/em>; |图片：Kneron&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;aiDngH&quot;>;在生成式人工智能的世界中，这是一场计算能力之战，需要获得最快、最强大的芯片。现在，人工智能边缘公司 Kneron 宣布将在今年年底前推出新的神经处理单元 (NPU) 芯片。 &lt;/p>; &lt;p id=&quot;nkjKNa&quot;>;Kneron 表示，名为 KL730 的 NPU 芯片将使运行大型语言模型 (LLM) 的成本降低，因为该处理器是专门为机器学习和人工智能应用而构建的。 &lt;/p>; &lt;p id=&quot;8hpmhl&quot;>;KL730 是 Kneron 的下一代处理器。 2021 年，该公司推出了支持 Transformer 模型的 KL530 芯片，这些模型支撑着一些生成式 AI 模型。 &lt;/p>; &lt;p id=&quot;ZU69Wl&quot;>;Kneron 首席执行官 Albert Liu 告诉 &lt;em>;The Verge&lt;/em>;，NPU 芯片是专门为人工智能设计的，不会强迫最初为处理图形而设计的东西工作这是对人工智能芯片制造商 Nvidia 的含蓄挖苦。&lt;/p>; &lt;p id=&quot;5k2T8c&quot;>;“我会说，如果你拥有像我们这样强大且轻量级的芯片，那么你可以带来像我们这样强大的 Transformer 模型GPT 适用于多种设备，”Liu 说。 &lt;/p>; &lt;p id=&quot;eA11P4&quot;>;Liu 不愿透露 KL730 的价格，但他指出，与 GPU 芯片相比，其 KL530 芯片的用户的运营成本下降了 75%。 &lt;/p>; &lt;p id=&quot;HVv8vw&quot;>;大多数人工智能公司和 &lt;a href=&quot;https://www.theverge.com/2023/7/26/23808730/aws-generative-ai-agents-healthcare-privacy &quot;>;云提供商纷纷涌向 Nvidia 的 H100&lt;/a>; Tensor Core GPU 芯片，因为人们认为 GPU 是最容易访问的处理器，能够编译运行生成式 AI 模型所需的计算。但即使拥有这种能力，通常也需要大量 H100 来运行一个大型语言模型，因此用户必须“分解”该模型才能使其运行。 &lt;/p>; &lt;p id=&quot;JSqmqk&quot;>;即便如此，随着需求持续增长，H100 的价格仍飙升至每块芯片 40,000 美元左右。 Nvidia 已经宣布计划发布&lt;a href=&quot;https://www.theverge.com/2023/8/8/23824690/nvidia-generative-ai-chip-gpu-gh200&quot;>;一款更强大的 AI 芯片&lt;/a >; 2024 年第二季度。竞争对手已经蓄势待发，&lt;a href=&quot;https://www.theverge.com/2023/8/1/23816405/amds-shovels-for-ai-gold- miners-are-coming-q4&quot;>;AMD 计划在今年第四季度发布&lt;/a>;自己的 AI 芯片。 &lt;/p>; &lt;p id=&quot;KZ6ExK&quot;>;Kneron 表示，与之前的芯片相比，KL730 的能效“实现了三到四倍的飞跃”，并且具有每秒 0.35 兆兆次运算的基础计算能力。 &lt;/p>; &lt;p id=&quot;n6Qebi&quot;>;该公司表示，新芯片还允许用户完全离线运行 LLM，无需连接到云提供商并更安全地处理数据。 &lt;/p>; </content><link href="https://www.theverge.com/2023/8/15/23832152/kneron-release-ai-chip-npu" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/15/23832152/kneron-release-ai-chip-npu</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-14T16:45:02-04:00</published><updated> 2023-08-14T16:45:02-04:00</updated><title>非营利组织表示，人工智能公司必须证明他们的人工智能是安全的</title><content type="html">&lt;图>; &lt;img alt=&quot;&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/AjLqwrZYPPDJLVjgZgeqATB9Ux4=/401x0:1640x826/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72544237 /acastro_181024_3045_data_privacy_US_0003.0.jpg&quot; />; &lt;figcaption>;由 Alex Castro / The Verge 绘制的插图&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;jwm9wi&quot;>;非营利组织问责技术、AI Now 和电子隐私信息中心 (EPIC) ）&lt;a href=&quot;https://accountabletech.org/wp-content/uploads/Zero-Trust-AI-Governance.pdf&quot;>;发布了政策提案&lt;/a>;，旨在限制大型人工智能公司在人工智能领域的权力。监管也可能扩大政府机构针对生成人工智能的某些用途的权力。 &lt;/p>; &lt;p id=&quot;pdfdwt&quot;>;该组织本月将该框架发送给主要在美国的政治家和政府机构，要求他们在制定围绕人工智能的新法律和法规时考虑该框架。&lt;/p>; &lt;p id =&quot;os7xO2&quot;>;该框架被他们称为“零信任人工智能治理”，它基于三个原则：执行现有法律；制定大胆、易于实施的明确规则；并让公司有责任证明人工智能系统在人工智能生命周期的每个阶段都不会有害。它对人工智能的定义涵盖了生成式人工智能和支持它的基础模型，以及算法决策。&lt;/p>; &lt;p id=&quot;R2qWl7&quot;>;“我们希望现在就推出该框架，因为这项技术正在快速发展。 ，但新法律不能以这样的速度发展，”Accountable Tech 联合创始人 Jesse Lehrich 告诉 &lt;em>;The Verge&lt;/em>;。 &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;GX5gy1&quot;>;&lt;q>;“但这让我们有时间减轻最大的伤害，因为我们找到了最好的方法来规范模型的预部署。”&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;bF5Mz0&quot;>;他补充说，随着选举季的临近，国会很快将开始竞选活动，留下人工智能监管的命运悬而未决。 &lt;/p>; &lt;p id=&quot;jTqd1O&quot;>;随着政府继续研究如何监管生成人工智能，该组织表示，现行有关反歧视、消费者保护和竞争的法律有助于解决当前的危害。 &lt;/p>; &lt;p id=&quot;qkIJSP&quot;>;人工智能领域的歧视和偏见是研究人员多年来一直警告的问题。 &lt;a href=&quot;https://www.rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/&quot;>;最近的&lt;em>;滚石&lt;/em>; &lt;/a>;&lt;em>; &lt;/em>;文章描述了 Timnit Gebru 等知名专家如何多年来就这个问题发出警报，但却被雇用他们的公司忽视。 &lt;/p>; &lt;p id=&quot;88MDGv&quot;>;Lehrich 指出 &lt;a href=&quot;https://www.theverge.com/2023/7/13/23793911/ftc-openai-investigation-consumer-ai-false -information&quot;>;联邦贸易委员会对 OpenAI 的调查&lt;/a>;作为利用现有规则发现潜在消费者伤害的一个例子。其他政府机构也警告人工智能公司，他们将密切关注 &lt;a href=&quot;https://www.theverge.com/2023/7/17/23798092/sec-chair-gensler-ai-will-impact- Financial-markets&quot;>;在特定领域使用人工智能&lt;/a>;。&lt;/p>; &lt;p id=&quot;RSC0YB&quot;>;国会已举行多次听证会，试图弄清楚如何应对生成式人工智能的兴起。 Senate Majority Leader Chuck Schumer &lt;a href=&quot;https://www.theverge.com/2023/6/21/23768257/ai-schumer-safe-innovation-framework-senate-openai-altman&quot;>;urged colleagues&lt;/a>; to “pick up the pace” in AI rulemaking. Big AI companies like &lt;a href=&quot;https://www.theverge.com/2023/5/16/23726119/congress-ai-hearing-sam-altman-openai&quot;>;OpenAI have been open&lt;/a>; to working with the US government to craft regulations and even signed a nonbinding, unenforceable &lt;a href=&quot;https://www.theverge.com/2023/7/21/23803244/meta-google-openai-microsoft-artificial-intelligence-ai-white-house-commitments&quot;>;agreement with the White House&lt;/a>; to develop responsible AI.&lt;/p>; &lt;p id=&quot;z0VuJt&quot;>;The Zero Trust AI framework also seeks to redefine the limits of &lt;a href=&quot;https://www.theverge.com/2023/5/18/23728423/supreme-court-section-230-gonzalez-google-twitter-taamneh-ruling&quot;>;digital shielding laws like Section 230&lt;/a>; so generative AI companies are held liable if the model spits out false or dangerous information. &lt;/p>; &lt;p id=&quot;mGTE9O&quot;>;“The idea behind Section 230 makes sense in broad strokes, but there is a difference between a bad review on Yelp because someone hates the restaurant and GPT making up defamatory things,” Lehrich says. (Section 230 was passed in part precisely to shield online services from liability over defamatory content, but there&#39;s little established precedent for whether platforms like ChatGPT can be held liable for generating &lt;a href=&quot;https://www.theverge.com/2023/6/9/23755057/openai-chatgpt-false-information-defamation-lawsuit&quot;>;false and damaging statements&lt;/a>;.)&lt;/p>; &lt;p id=&quot;fKtYmo&quot;>;And as lawmakers continue to meet with AI companies, fueling &lt;a href=&quot;https://www.theverge.com/2023/5/19/23728174/ai-regulation-senate-hearings-regulatory-capture-laws&quot;>;fears of regulatory capture&lt;/a>;, Accountable Tech and its partners suggested several bright-line rules, or policies that are clearly defined and leave no room for subjectivity. &lt;/p>; &lt;p id=&quot;OMyfor&quot;>;These include prohibiting AI use for emotion recognition, predictive policing, facial recognition used for mass surveillance in public places, social scoring, and fully automated hiring, firing, and HR management. They also ask to ban collecting or processing unnecessary amounts of sensitive data for a given service, collecting biometric data in fields like education and hiring, and “surveillance advertising.”&lt;/p>; &lt;p id=&quot;31b18i&quot;>;Accountable Tech also urged lawmakers to prevent large cloud providers from owning or having a beneficial interest in large commercial AI services to &lt;a href=&quot;https://www.theverge.com/2023/8/8/23820423/ai-startups-regulation-big-tech&quot;>;limit the impact of Big Tech&lt;/a>; companies in the AI ecosystem. Cloud providers such as Microsoft and Google have an outsize influence on generative AI. OpenAI, the most well-known generative AI developer, works with Microsoft, which also invested in the company. Google released its large language model Bard and is developing other AI models for commercial use. &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;OXIUA0&quot;>;&lt;q>;Accountable Tech and its partners want companies working with AI to prove large AI models will not cause overall harm&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;17yLaG&quot;>;The group proposes a method similar to one used in the pharmaceutical industry, where companies submit to regulation even before deploying an AI model to the public and ongoing monitoring after commercial release. &lt;/p>; &lt;p id=&quot;2fXqa4&quot;>;The nonprofits do not call for a single government regulatory body. However, Lehrich says this is a question that lawmakers must grapple with to see if splitting up rules will make regulations more flexible or bog down enforcement. &lt;/p>; &lt;p id=&quot;tCuCZj&quot;>;Lehrich says it&#39;s understandable smaller companies might balk at the amount of regulation they seek, but he believes there is room to tailor policies to company sizes. &lt;/p>; &lt;p id=&quot;SZOMkD&quot;>;“Realistically, we need to differentiate between the different stages of the AI supply chain and design requirements appropriate for each phase,” he says. &lt;/p>; &lt;p id=&quot;7G7LSL&quot;>;He adds that developers using open-source models should also make sure these follow guidelines. &lt;/p>; </content><link href="https://www.theverge.com/2023/8/14/23831819/ai-companies-regulation-rules-shield-laws" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/14/23831819/ai-companies-regulation-rules-shield-laws</id><author><name> Emilia David</name></author></entry></feed>