<feed xml:lang="en" xmlns="http://www.w3.org/2005/Atom"><title>边缘 - 人工智能</title><icon>https://cdn.vox-cdn.com/community_logos/52801/VER_Logomark_32x32..png</icon><updated> 2023-08-14T16:45:02-04:00</updated><id> https://www.theverge.com/rss/ai-artificial-intelligence/index.xml </id><link href="https://www.theverge.com/ai-artificial-intelligence" rel="alternate" type="text/html"/><entry><published> 2023-08-14T16:45:02-04:00</published><updated> 2023-08-14T16:45:02-04:00</updated><title>非营利组织表示，人工智能公司必须证明他们的人工智能是安全的</title><content type="html">&lt;图>; &lt;img alt=&quot;&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/AjLqwrZYPPDJLVjgZgeqATB9Ux4=/401x0:1640x826/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72544237 /acastro_181024_3045_data_privacy_US_0003.0.jpg&quot; />; &lt;figcaption>;由 Alex Castro / The Verge 绘制的插图&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;jwm9wi&quot;>;非营利组织问责技术、AI Now 和电子隐私信息中心 (EPIC) ）&lt;a href=&quot;https://accountabletech.org/wp-content/uploads/Zero-Trust-AI-Governance.pdf&quot;>;发布了政策提案&lt;/a>;，旨在限制大型人工智能公司在人工智能领域的权力。监管也可能扩大政府机构针对生成人工智能的某些用途的权力。 &lt;/p>; &lt;p id=&quot;pdfdwt&quot;>;该组织本月将该框架发送给主要在美国的政治家和政府机构，要求他们在制定围绕人工智能的新法律和法规时考虑该框架。&lt;/p>; &lt;p id =&quot;os7xO2&quot;>;该框架被他们称为“零信任人工智能治理”，它基于三个原则：执行现有法律；制定大胆、易于实施的明确规则；并让公司有责任证明人工智能系统在人工智能生命周期的每个阶段都不会有害。它对人工智能的定义涵盖了生成式人工智能和支持它的基础模型，以及算法决策。&lt;/p>; &lt;p id=&quot;R2qWl7&quot;>;“我们希望现在就推出该框架，因为这项技术正在快速发展。 ，但新法律不能以这样的速度发展，”Accountable Tech 联合创始人 Jesse Lehrich 告诉 &lt;em>;The Verge&lt;/em>;。 &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;GX5gy1&quot;>;&lt;q>;“但这让我们有时间减轻最大的伤害，因为我们找到了最好的方法来规范模型的预部署。”&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;bF5Mz0&quot;>;他补充说，随着选举季的临近，国会很快将开始竞选活动，留下人工智能监管的命运悬而未决。 &lt;/p>; &lt;p id=&quot;jTqd1O&quot;>;随着政府继续研究如何监管生成人工智能，该组织表示，现行有关反歧视、消费者保护和竞争的法律有助于解决当前的危害。 &lt;/p>; &lt;p id=&quot;qkIJSP&quot;>;人工智能领域的歧视和偏见是研究人员多年来一直警告的问题。 &lt;a href=&quot;https://www.rollingstone.com/culture/culture-features/women-warnings-ai-danger-risk-before-chatgpt-1234804367/&quot;>;最近的&lt;em>;滚石&lt;/em>; &lt;/a>;&lt;em>; &lt;/em>;文章描述了 Timnit Gebru 等知名专家如何多年来就这个问题发出警报，但却被雇用他们的公司忽视。 &lt;/p>; &lt;p id=&quot;88MDGv&quot;>;Lehrich 指出 &lt;a href=&quot;https://www.theverge.com/2023/7/13/23793911/ftc-openai-investigation-consumer-ai-false -information&quot;>;联邦贸易委员会对 OpenAI 的调查&lt;/a>;作为利用现有规则发现潜在消费者伤害的一个例子。其他政府机构也警告人工智能公司，他们将密切关注 &lt;a href=&quot;https://www.theverge.com/2023/7/17/23798092/sec-chair-gensler-ai-will-impact- Financial-markets&quot;>;在特定领域使用人工智能&lt;/a>;。&lt;/p>; &lt;p id=&quot;RSC0YB&quot;>;国会已举行多次听证会，试图弄清楚如何应对生成式人工智能的兴起。参议院多数党领袖查克·舒默&lt;a href=&quot;https://www.theverge.com/2023/6/21/23768257/ai-schumer-safe-innovation-framework-senate-openai-altman&quot;>;敦促同事&lt;/a >; 在人工智能规则制定中“加快步伐”。像 &lt;a href=&quot;https://www.theverge.com/2023/5/16/23726119/congress-ai-hearing-sam-altman-openai&quot;>;OpenAI 这样的大型人工智能公司已经对合作持开放态度&lt;/a>;与美国政府一起制定法规，甚至签署了一项不具约束力、不可执行的&lt;a href=&quot;https://www.theverge.com/2023/7/21/23803244/meta-google-openai-microsoft-artificial-intelligence-ai -white-house-commitments&quot;>;与白宫达成协议&lt;/a>;，开发负责任的人工智能。&lt;/p>; &lt;p id=&quot;z0VuJt&quot;>;零信任人工智能框架还试图重新定义&lt;a href= “https://www.theverge.com/2023/5/18/23728423/supreme-court-section-230-gonzalez-google-twitter-taamneh-ruling&quot;>;像第 230 条这样的数字屏蔽法&lt;/a>;如此具有生成性如果模型吐出虚假或危险信息，人工智能公司将承担责任。 &lt;/p>; &lt;p id=&quot;mGTE9O&quot;>;“第 230 条背后的想法从广义上讲是有道理的，但 Yelp 上因为有人讨厌这家餐厅而做出的差评与 GPT 编造诽谤性内容之间是有区别的，”Lehrich 说。 （第 230 条的通过在一定程度上正是为了保护在线服务免受诽谤性内容的责任，但对于像 ChatGPT 这样的平台是否可以为生成 &lt;a href=&quot;https://www.theverge.com/2023 /6/9/23755057/openai-chatgpt-false-information-defamation-lawsuit&quot;>;虚假且具有破坏性的陈述&lt;/a>;。）&lt;/p>; &lt;p id=&quot;fKtYmo&quot;>;随着立法者继续与人工智能会面公司，加剧了&lt;a href=&quot;https://www.theverge.com/2023/5/19/23728174/ai-regulation-senate-hearings-regulatory-capture-laws&quot;>;对监管捕获的恐惧&lt;/a>;， Accountable Tech 及其合作伙伴提出了几条明确的规则或明确定义的政策，不留任何主观空间。 &lt;/p>; &lt;p id=&quot;OMyfor&quot;>;其中包括禁止人工智能用于情绪识别、预测性警务、用于公共场所大规模监控的面部识别、社会评分以及全自动招聘、解雇和人力资源管理。他们还要求禁止为特定服务收集或处理不必要的敏感数据，禁止在教育和招聘等领域收集生物识别数据，以及“监视广告”。&lt;/p>; &lt;p id=&quot;31b18i&quot;>;Accountable Tech 还敦促立法者阻止大型云提供商拥有大型商业人工智能服务或在大型商业人工智能服务中拥有实益权益&lt;a href=&quot;https://www.theverge.com/2023/8/8/23820423/ai-startups-regulation-big- tech&quot;>;限制大型科技公司在人工智能生态系统中的影响。微软和谷歌等云提供商对生成人工智能有着巨大的影响力。 OpenAI是最著名的生成式人工智能开发商，与微软合作，微软也投资了该公司。谷歌发布了大型语言模型Bard，并正在开发其他商业用途的人工智能模型。 &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;OXIUA0&quot;>;&lt;q>;Accountable Tech 及其合作伙伴希望与人工智能合作的公司证明大型人工智能模型不会造成总体危害&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;17yLaG&quot;>;该组织提出了一种类似于制药行业使用的方法，即公司在向公众部署人工智能模型之前就必须遵守监管规定以及商业发布后的持续监控。 &lt;/p>; &lt;p id=&quot;2fXqa4&quot;>;非营利组织不需要单一的政府监管机构。然而，莱里奇表示，这是立法者必须解决的一个问题，看看分割规则是否会使法规更加灵活或阻碍执行。 &lt;/p>; &lt;p id=&quot;tCuCZj&quot;>;Lehrich 表示，小公司可能会对他们寻求的监管力度犹豫不决，这是可以理解的，但他认为还有根据公司规模调整政策的空间。 &lt;/p>; &lt;p id=&quot;SZOMkD&quot;>;“实际上，我们需要区分人工智能供应链的不同阶段以及适合每个阶段的设计要求，”他说。 &lt;/p>; &lt;p id=&quot;7G7LSL&quot;>;他补充说，使用开源模型的开发人员还应确保这些遵循准则。 &lt;/p>; </content><link href="https://www.theverge.com/2023/8/14/23831819/ai-companies-regulation-rules-shield-laws" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/14/23831819/ai-companies-regulation-rules-shield-laws</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-14T15:27:52-04:00</published><updated> 2023-08-14T15:27:52-04:00</updated><title> Humane 将在 10 月月食的同一天分享更多关于其神秘的“Ai Pin”的信息</title><content type="html">&lt;figure>; &lt;img alt=&quot;Imran Chaudhri 的 TED 演讲中关于人性化 Ai Pin 的照片。该设备将电话的详细信息投射到他的手上。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/LqH2FkgtoVu1buxgqH7GLc9NCh0=/150x0:1770x1080/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72543975/The_Disappearing_Computer__An_Exclusive_Preview_of_ Humane_s_Screenless_Tech____Imran_Chaudhri____TED_____The_Disappearing_Computer__An_Exclusive_Preview_of_Humane_s_Screenless_Tech___Imran_Chaudhri___TED_2023_8_14_12017.62_1080p_streamsho.0.png&quot; />; &lt;figcaption>;图片：TED&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;npYRUJ&quot;>;Humane 是一家由前苹果员工创立的初创公司，计划在同一天分享更多有关其神秘的人工智能可穿戴设备的信息作为 10 月份的日食，联合创始人 Imran Chaudhri 在公司 Discord 上的一段视频中说道 (&lt;a href=&quot;https://www.inverse.com/tech/ humane-ai-pin-october-14-2023-公告&quot;>;通过&lt;em>;Inverse&lt;/em>;&lt;/a>;）。日食预计将于 &lt;a href=&quot;https://solarsystem.nasa.gov/eclipses/2023/oct-14-annular/where-when/&quot;>;10 月 14 日&lt;/a>;发生。&lt;/p>; &lt;p id=&quot;3Mi4Wh&quot;>;该设备，正式名称为&lt;a href=&quot;https://www.theverge.com/2023/6/30/23779654/ humane-ai-pin-name-launch-date&quot;>; “Humane Ai Pin”&lt;/a>;（在 Discord 视频中，Chaudhri 发音中间的单词就像你说 AI 这个词一样），正在被宣传为可以取代智能手机的东西。 &lt;a href=&quot;https://youtu.be/gMsQO5u7-NQ&quot;>;在今年 TED 会议上的一次疯狂演示&lt;/a>;中，Chaudhri 使用该设备（以某种方式固定在他的夹克上，高度与胸部高度）来执行以下操作：例如：&lt;/p>; &lt;ul>; &lt;li id=&quot;LH3jck&quot;>;接听他的妻子、Humane 联合创始人 Bethany Bongiorno 打来的电话，但无需按接听按钮。 （他确实说了“你好？”，这可能是设备用来接听电话的提示）&lt;/li>; &lt;li id=&quot;keXq6M&quot;>;使用人工智能制作的声音版本用法语说出翻译后的句子，尽管没有口头指定他想要英语到法语的翻译&lt;/li>; &lt;li id=&quot;wSGKJV&quot;>;查看一些电子邮件、事件和消息，但目前还不清楚设备从哪里获取数据它显然不需要与智能手机配对&lt;/li>; &lt;/ul>; &lt;p id=&quot;1mzrP4&quot;>;正如您可能知道的那样，我们有&lt;a href=&quot;https://www.theverge. com/2023/5/9/23716996/ humane-wearable-ai-tech-demo-ted-video&quot;>;很多关于爱品的问题&lt;/a>;！希望即将到来的 10 月 14 日这一时刻能够为其中一些问题提供更多线索。 &lt;/p>; &lt;div id=&quot;9XDp50&quot;>;&lt;div style=&quot;left: 0; 宽度: 100%; height: 0; 位置: 相对; padding-bottom: 56.25%;&quot;>;&lt;iframe src=&quot;https: //www.youtube.com/embed/gMsQO5u7-NQ?rel=0&quot; style=&quot;顶部：0；左侧：0；宽度：100%；高度：100%；位置：绝对；边框：0；&quot; allowfullscreen =“”滚动=“否”allow=“加速度计；剪贴板写入；加密媒体；陀螺仪；画中画；网络共享；”>;&lt;/iframe>;&lt;/div>;&lt;/div>; &lt;p id=&quot;EBOIyH&quot;>;“十月将发生令人难以置信的天体事件：日食，”Chaudhri 在 Discord 视频中说道。 “日食对我们来说是一个重要的象征。这是精神上的新开始，就是这个意思。这是全世界都注意到并聚集在一起的事情。我们当然期待能够在这一天度过一个特殊的时刻。”&lt;/p>; &lt;p id=&quot;Oi4iXT&quot;>;“我们所有人都迫不及待地想要走在街上， Bongiorno 说道。&lt;/p>; &lt;p id=&quot;JmZiQV&quot;>;如果您想亲自听听他们的评论，我们已在下面嵌入了来自 Humane Discord 的视频。&lt; /p>; &lt;div id=&quot;Gyu1pb&quot;>; &lt;div data-analytics-viewport=&quot;video&quot; data-analytics-action=&quot;volume:view:article:middle&quot; data-analytics-label=&quot;来自 Discord 的人性化更新|113071 “data-volume-uuid =“ff9cb1e96”data-volume-id =“113071”data-analytics-placement =“文章：中间”data-volume-placement =“文章”data-volume-autoplay =“假”id = “volume-placement-476”class=&quot;volume-video&quot;>;&lt;/div>; &lt;/div>; </content><link href="https://www.theverge.com/2023/8/14/23831756/humane-ai-pin-october-solar-eclipse" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/14/23831756/ humane-ai-pin-october-solar-eclipse</id><author><name>杰·彼得斯</name></author></entry><entry><published>2023-08-14T11:25:58-04:00</published><updated> 2023-08-14T11:25:58-04:00</updated><title>亚马逊添加了人工智能生成的评论摘要，因此您无需阅读评论</title><content type="html">&lt;figure>; &lt;img alt=&quot;亚马逊文字标记的插图，背景为橙色、黑色和棕褐色，由重叠线条组成。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/RVQwMVlcFM032vy7JaflTE1KHDc=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72543131/acastro_STK103__03.0.jpg&quot;/>; &lt;figcaption>;插图由 Alex Castro / The Verge 提供&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;uF3Ylp&quot;>;亚马逊正在使用人工智能来更轻松地判断产品是否好用。该公司现在&lt;a href=&quot;https://www.aboutamazon.com/news/amazon-ai/amazon-improves-customer-reviews-with-generative-ai&quot;>;推出&lt;/a>;人工智能生成的评论摘要，将成百上千条亚马逊评论归结为一段简介，解释大多数人喜欢或不喜欢某产品的哪些方面。&lt;/p>; &lt;p id=&quot;4dIcHl&quot;>;这些摘要已经过至少一段时间的测试几个月后，它们现在可以通过亚马逊的移动应用程序更广泛地提供给美国的“子集”用户。亚马逊表示，它们“涵盖多种产品”。到目前为止，我们已经在电视、耳机、平板电脑和健身追踪器上看到了它们。但该功能的可用性并不完全一致。 Galaxy Tab A7 有评论摘要，但较新的 Galaxy Tab A8 没有。&lt;/p>; &lt;p id=&quot;XwoFjZ&quot;>;亚马逊的摘要很容易阅读，但确实包含一些偶尔的语言怪癖。他们似乎也主要关注产品的优点，较少花时间在缺点上，并将其留到最后。也就是说，这可能是因为亚马逊的搜索已经提升了评价较高的产品，因此很难找到人们特别沮丧的任何内容的摘要。以下是一些示例的屏幕截图。&lt;/p>; &lt;div class=&quot;c-wide-block&quot;>;&lt;div class=&quot;c-image-grid&quot;>; &lt;div class=&quot;c-image-grid__item&quot;>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot;“客户喜欢电视的颜色。他们说颜色大胆、逼真，黑色深邃。客户还欣赏产品的画质、质量和价值然而，一些客户对亮度、音质、性能和设置的便捷性有不同的看法。”&quot; data-mask-text=&quot;false&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/KipYhJ -TTADRDdkyQl7hIM0ZmPk=/400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24849767/Screenshot_20230814_104940.jpg&quot;>; &lt;figcaption>;&lt;em>;亚马逊对 LG C2 55 英寸 OLED 电视的摘要。 &lt;/em>;&lt;/figcaption>; &lt;/figure>; &lt;/div>; &lt;div class=&quot;c-image-grid__item&quot;>; &lt;figure class=&quot;e-image&quot;>; &lt;img alt=&quot;“客户喜欢耳机。他们说再生塑料的外观有其自身的魅力，而且不会让你看起来很愚蠢。顾客也很欣赏环形和开放式设计。音质比想象中好，耳机佩戴舒适。然而，一些客户对稳定性感到失望。客户对电池寿命、质量、音质、性能、贴合度和舒适度有不同的看法。”&quot; data-mask-text=&quot;false&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/BpOIOMx_BgQbjzbBLvcuhF7PMTs= /400x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24849768/Screenshot_20230814_105120.jpg&quot;>; &lt;figcaption>;&lt;em>;亚马逊对索尼 LinkBuds 耳机的总结。&lt;/em>;&lt;/figcaption >; &lt;/figure>; &lt;/div>; &lt;/div>;&lt;/div>; &lt;p id=&quot;qXuCHe&quot;>;该功能位于移动设备评论部分顶部的“客户评价”标题下。最后，该段落包含一条注释，表明它是人工智能生成的。亚马逊表示，这些摘要仅从经过验证的购买中提取，以减少虚假评论。该系统还包括评论突出显示过滤器，您可以点击这些过滤器来查找实际的评论涉及这些功能或问题的评论。&lt;/p>; &lt;p id=&quot;8wMcFB&quot;>;总结客户评论已成为生成式 AI 更明显、更容易实现的用途之一。Newegg &lt;a href=&quot;https ://www.theverge.com/2023/8/9/23825805/newegg-chatgpt-review-summaries-ai&quot;>;上周推出了类似的功能&lt;/a>;，微软&lt;a href=&quot;https:// www.theverge.com/2023/5/23/23732821/microsoft-store-bing-ai-hub-apps-build&quot;>;5 月份在 Microsoft Store 中添加了 AI 摘要&lt;/a>;。随着更多平台推出此功能，对于用户来说，最大的问题是他们在多大程度上可以信任来自明显试图向他们推销东西的服务的摘要。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/14/23831391/amazon-review-summaries-generative-ai" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/14/23831391/amazon-review-summaries-generative-ai</id><author><name>雅各布·卡斯特雷纳克斯</name></author></entry><entry><published>2023-08-14T06:26:27-04:00</published><updated> 2023-08-14T06:26:27-04:00</updated><title>纽约时报禁止使用其内容来训练人工智能模型</title><content type="html">&lt;figure>; &lt;img alt=&quot;2023 年 8 月 7 日纽约市人们走在《纽约时报》前&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/9R2whxZtEYBqrL7tCb5tBl07fS4=/82x0:3418x2224 /1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72541872/1599689892.0.jpg&quot; />; &lt;figcaption>;&lt;em>;拒绝遵守限制可能会导致未具体说明的罚款或处罚。&lt;/em>; |摄影：Kena Betancur/VIEWpress&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;m1glZY&quot;>;&lt;em>;《纽约时报》&lt;/em>;已采取先发制人的措施，阻止其内容被用于训练人工智能模型。据&lt;a href=&quot;https://www.adweek.com/media/the-new-york-times-updates-terms-of-service-to-prevent-ai-scraping-its-content/&quot;>;报道&lt;em>;Adweek&lt;/em>;&lt;/a>;，&lt;em>;纽约时报&lt;/em>;更新了其&lt;a href=&quot;https://help.nytimes.com/hc/en-us/articles/115014893428-Terms -of-Service&quot;>;服务条款&lt;/a>;于 8 月 3 日禁止其内容（包括文本、照片、图像、音频/视频剪辑、“外观和感觉”、元数据或汇编）用于开发“任何软件程序，包括但不限于训练机器学习或人工智能（AI）系统。”&lt;/p>; &lt;p id=&quot;sM72n6&quot;>;更新后的条款现在还指定网站等自动化工具未经出版物书面许可，不得使用旨在使用、访问或收集此类内容的爬虫。 《纽约时报》表示，拒绝遵守这些新限制可能会导致未具体说明的罚款或处罚。尽管在其政策中引入了新规则，但该出版物似乎并未对其 &lt;a href=&quot;https://www.nytimes.com/robots.txt&quot;>;robots.txt&lt;/a>; 进行任何更改 -该文件通知搜索引擎抓取工具可以访问哪些网址。&lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;VPED7u&quot;>;&lt;q>;Google 最近授予了自己权限根据从网络收集的公共数据来训练其人工智能服务。&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;sOQ3Xf&quot;>;此举可能是为了响应 Google 隐私政策的最新更新，该更新披露了&lt;a href=&quot;https://www.theverge.com/2023/7/5/23784257/google-ai-bard-privacy-policy-train-web-scraping&quot;>;搜索巨头可能会收集公共数据&lt;/a >; 从网络上训练其各种 AI 服务，例如 Bard 或 Cloud AI。许多大型语言模型为流行的人工智能服务提供支持，例如 &lt;a href=&quot;https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-close-research-ilya-sutskever-interview&quot; >;OpenAI 的 ChatGPT&lt;/a>; 在大量数据集上进行了训练，这些数据集可能包含未经原始创建者许可从网络上抓取的受版权保护或以其他方式保护的材料。&lt;/p>; &lt;p id=&quot;0wvFGV&quot;>;也就是说，&lt;em>;NYT &lt;/em>;还与 Google 签署了价值 1 亿美元的协议 &lt;a href=&quot;https://www.nytco.com/press/the-new-york-times-company-and-google-expand-agreement-on-news -and-innovation/&quot;>;早在二月份&lt;/a>;就允许这家搜索巨头在未来三年内在其一些平台上展示《时代》内容。该出版物称，两家公司将共同开发内容分发、订阅、营销、广告和“实验”工具，因此《纽约时报》服务条款的变更可能是针对其他公司的比如 OpenAI 或微软。 &lt;a href=&quot;https://www.nytco.com/press/the-new-york-times-company-and-google-expand-agreement-on-news-and-innovation/&quot;>;&lt;em>;Semafor &lt; /em>;周日报道&lt;/a>;，&lt;em>;泰晤士报&lt;/em>;已退出试图与科技公司就人工智能培训数据进行联合谈判的媒体联盟 - 这意味着如果它确实与公司达成协议，它根据具体情况，可能性更大。&lt;/p>; &lt;p id=&quot;xjGV0A&quot;>;OpenAI 最近宣布，网站运营商现在可以&lt;a href=&quot;https://www.theverge.com/2023/ 8/7/23823046/openai-data-scrape-block-ai&quot;>;阻止其 GPTBot 网络爬虫&lt;/a>;抓取其网站。微软还&lt;a href=&quot;https://venturebeat.com/ai/microsoft-changes-services-agreement-to-add-restrictions-for-ai-offerings/&quot;>;为其自己添加了一些新的限制&lt;/a>;条款和条件禁止人们使用其人工智能产品“创建、训练或改进（直接或间接）任何其他人工智能服务”，同时禁止用户从其人工智能工具中抓取或以其他方式提取数据。&lt;/p>; &lt;p id=&quot;mBXbXX&quot;>;本月早些时候，包括美联社和欧洲出版商委员会在内的多家新闻机构&lt;a href=&quot;https://www.theverge. com/2023/8/10/23827316/news-transparency-copyright-generative-ai&quot;>;签署了一封公开信&lt;/a>;，呼吁全球立法者制定规则，要求训练数据集透明并获得权利持有者的同意使用数据进行训练。&lt;/p>; &lt;p id=&quot;ifMlWr&quot;>;&lt;em>;&lt;strong>;更新东部时间上午 10:15：&lt;/strong>;&lt;/em>;&lt;em>;添加了关于 &lt;/em>;Times 的报告&lt; em>; 退出就人工智能数据使用进行谈判的媒体联盟。&lt;/em>;&lt;/p>; </content><link href="https://www.theverge.com/2023/8/14/23831109/the-new-york-times-ai-web-scraping-rules-terms-of-service" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/14/23831109/the-new-york-times-ai-web-scraping-rules-terms-of-service</id><author><name>杰西韦瑟贝德</name></author></entry><entry><published>2023-08-11T14:30:00-04:00</published><updated> 2023-08-11T14:30:00-04:00</updated><title>微软的 Copilot AI 现在可以帮助部署现场工作人员</title><content type="html">&lt;figure>; &lt;img alt=&quot;Microsoft Office 库存图像&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/cJJwwawvPi5SCqcOJVCEyTNDrzo=/0x2:640x429/1310x873/cdn.vox-cdn.com/uploads/chorus_image /image/72535865/Microsoft-campus.0.jpg&quot; />; &lt;/figure>; &lt;p id=&quot;XVsjqJ&quot;>;微软通过将 Copilot AI 助手集成到其现场服务平台中，简化工作流程，为一线现场工作人员带来生成式 AI还可以让主管了解技术人员在工作中正在做什么。 &lt;/p>; &lt;p id=&quot;mJv7ca&quot;>;副驾驶，&lt;a href=&quot;https://www.theverge.com/2023/3/16/23642833/microsoft-365-ai-copilot-word-outlook-teams &quot;>;于 3 月份首次推出&lt;/a>;，现已在 Microsoft 365 企业平台上使用，并且首先由需要 AI 为 PowerPoint 演示文稿生成文本的坐在办公桌前的员工使用。 （它与同名的 Github 服务不同。）现在，Copilot 将被添加到 Dynamics 365 服务中，供电缆技术人员和电气维修人员等现场工作人员以及设施、制造和医疗保健领域的其他工作人员使用。 &lt;/p>; &lt;p id=&quot;i5eAUk&quot;>;使用 Copilot，通过 Outlook 发送的服务请求将自动预填充信息，包括同一客户之前联系服务的次数。主管可以在将工单发送给现场工作人员之前对其进行审查。到今年秋季，这些工作订单还将根据出差时间、可用性和技能来推荐特定的人员来完成该工作。 &lt;/p>; &lt;p id=&quot;dC5Wny&quot;>;技术人员可以更新他们的工作状态，即他们是否已到达某个位置并开始解决问题以及问题到底是什么，以便管理人员知道项目发生了什么情况，并了解他们的情况。可以帮助确定任务的优先顺序。它还可以让他们以更少的点击次数找到工作地点信息。然后，Copilot 将帮助经理回顾服务内容。 &lt;/p>; &lt;p id=&quot;H1KXni&quot;>;客户将更清楚地了解他们的技术人员在哪里，现场工作人员消除了许多繁忙的工作。但我们已经看到，高科技工具可以使工人的活动更加明显，也可以鼓励对工人进行更严格的审查，例如，&lt;a href=&quot;https://www.theverge.com/2019/10/23/20929524 /google-surveillance-tool-accused-employee-activism-protests-union-organizing&quot;>;Google 员工投诉&lt;/a>;涉嫌通过新日历工具进行间谍活动。 &lt;/p>; &lt;p id=&quot;uIGoEr&quot;>;如果技术人员遇到问题，微软可以通过移动设备将 3D 空间注释引入 Teams 视频通话中，这样可以通过在视频通话中圈出有问题的螺丝来强调问题，节省了工作人员来回描述他们所看到的内容的时间。如果相机移开，注释也会移开。它似乎与 &lt;a href=&quot;https://www.theverge.com/2022/12/15/23510670/microsoft-hololens-2-teams-features-integration&quot;>;HoloLens 2 Teams 视频中的远程协助功能类似&lt;/a>;。&lt;/p>; &lt;p id=&quot;nHOZRg&quot;>;微软业务应用程序和平台公司副总裁 Lili Cheng 表示，将生成式人工智能引入现场工作可以让技术人员等一线工作人员更快、更智能地工作。&lt;/a>; p>; &lt;p id=&quot;w92tKV&quot;>;“许多现场工作人员经常依赖笔和纸，大多数工具都是碎片化的，因此需要很长时间才能完成工作，”Cheng 告诉 &lt;em>;The Verge&lt;/em>; 。 “我们希望帮助简化他们的工作流程。” &lt;/p>; &lt;p id=&quot;fr2Tn1&quot;>;Dynamics 365 中的 Copilot 已可供当前用户使用。在测试该产品时，Microsoft 与 Hitachi Solutions、9altitudes Group 和 TechLabs London 等全球客户合作。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/11/23828556/microsoft-generative-ai-frontline-workers" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/11/23828556/microsoft-generative-ai-frontline-workers</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-11T13:06:15-04:00</published><updated> 2023-08-11T13:06:15-04:00</updated><title> Zoom 重写了其政策，明确表示您的视频不会用于训练 AI 工具</title><content type="html">&lt;figure>; &lt;img alt=&quot;蓝色和黑色背景上的 Zoom 徽标插图。&quot; src =“https://cdn.vox-cdn.com/thumbor/oqggTtsLZxUpX-v-JC-g3ioYZH8=/0x0:2040x1360/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72535548/acastro_STK059_zoom_03。 0.jpg&quot; />; &lt;figcaption>;由 Alex Castro / The Verge 绘制的插图&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;goopgK&quot;>;Zoom 更新了其服务条款，并重新措辞了解释最近服务条款变更的博客文章参考其生成式人工智能工具。该公司现在明确表示，“类似通信”的客户数据不会用于为 Zoom 或第三方训练人工智能模型。类通信涵盖哪些内容？基本上，就是 Zoom 上视频会议的内容。 &lt;/p>; &lt;p id=&quot;29hnbl&quot;>;以下是&lt;a href=&quot;https://explore.zoom.us/en/terms/&quot;>;新修订的条款&lt;/a>;的关键段落：&lt;/ p>; &lt;blockquote>;&lt;p id=&quot;I0tXWk&quot;>;Zoom 不会使用您的任何音频、视频、聊天、屏幕共享、附件或其他通信类客户内容（例如投票结果、白板和反应）来训练 Zoom或第三方人工智能模型。&lt;/p>;&lt;/blockquote>; &lt;p id=&quot;fAQfod&quot;>;Zoom 因服务条款语言而受到审查，人们将其解释为赋予公司广泛的客户数据控制权和版权，包括可能是他们在通话期间展示或讨论的任何内容，目的是使用该内容来训练人工智能模型，以支持其 &lt;a href=&quot;https://www.theverge.com/2023/3/27/23658047/ 等功能Zoom-ai-features-meeting-summaries-mail-calendar&quot;>;会议摘要&lt;/a>;。 &lt;/p>; &lt;p id=&quot;VqJZ0k&quot;>;服务条款第 10 条（之前的语言）也已被重写，以更清楚地区分“客户内容”和“服务生成的数据”。&lt;/p >; &lt;p id=&quot;ePnFVh&quot;>;Zoom 表示，在该公司本周早些时候修改了条款以试图安抚客户之后，更新后的政策只是更明确地重申其立场。在周五的修订之前，最新版本称，“未经您的同意，Zoom 不会使用音频、视频或聊天客户内容来训练我们的人工智能模型”，但没有明确说明它将使用什么或如何给予同意。&lt;/ p>; &lt;p id=&quot;rHgMIK&quot;>;周一，Zoom 首席产品官 Smita Hashim 更新了有关这些变化的博客文章，表示“我们的客户继续拥有和控制他们的内容。” &lt;a href=&quot;https://web.archive.org/web/20230807115434/https://blog.zoom.us/zooms-term-service-ai/&quot;>;Hashim 博文的旧版本&lt;/a>;有更多关于 Zoom 如何使用客户数据“提供增值服务”的示例，其中不包括训练自己的模型，例如获得提供会议录音的许可证以及使用自动扫描仪来检测欺诈或垃圾邮件.&lt;/p>; &lt;p id=&quot;RVNVy5&quot;>;不过，这并不是人们第一次&lt;a href=&quot;https://www.theverge.com/2012/12/21/3791786/why-the- instagram-debacle-just-taught-every-tech-company-to-be&quot;>;筹集了&lt;/a>; &lt;a href=&quot;https://www.theverge.com/2012/4/25/2973849/google-drive -terms-privacy-data-skydrive-dropbox-icloud&quot;>;对看似广泛的服务条款变化的担忧，我认为 Zoom 最初可以在这里做更多的事情来向用户澄清这一点。随着人们越来越担心公司如何使用数据来训练人工智能模型，这绝对不会是最后一次。&lt;/p>; &lt;p id=&quot;f8JWXW&quot;>;&lt;/p>; &lt;p id=&quot;mt2Ova&quot;>; &lt;/p >; </content><link href="https://www.theverge.com/2023/8/11/23828649/zoom-communications-like-data-train-ai-artificial-intelligence-models" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/11/23828649/zoom-communications-like-data-train-ai-artificial-intelligence-models</id><author><name>杰·彼得斯</name></author></entry><entry><published>2023-08-10T17:02:35-04:00</published><updated> 2023-08-10T17:02:35-04:00</updated><title> Augie 让你可以用人工智能克隆你自己的声音来制作视频</title><content type="html">&lt;figure>; &lt;img alt=&quot;手持麦克风&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/vqHwu7QdP76vvYoLE5Em8RSSt94=/0x15:640x442/1310x873/cdn.vox-cdn.com/uploads/chorus_image /image/72532894/4600812139_1c67b0c9c1_z.0.jpg&quot; />; &lt;figcaption>;图片：Daniela Vladimirova / Flickr&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;ZtAf0H&quot;>;8 月发布了基于人工智能的视频创作平台 Augie结合语音克隆功能，无需预订录音室即可阅读广告文案。 &lt;/p>; &lt;p id=&quot;qlGSFr&quot;>;与 ElevenLabs 合作，Aug X 让用户录制自己或他人的声音，并将其克隆以用于其他短视频。 Augie 平台主要针对营销人员和社交媒体团队，让人们可以快速向视频添加旁白、照片、文本和音乐，而无需学习音频和视频编辑。 &lt;/p>; &lt;p id=&quot;P37RG1&quot;>;Aug X 的创始人 Jeremy Toeman 表示，在意识到有些人不喜欢对着麦克风说话或录制画外音后，该公司希望添加语音克隆功能。&lt;/p>; >; &lt;p id=&quot;tNsAMx&quot;>;“你会对使用我们的语音克隆功能的人数感到惊讶，因为他们不喜欢录制旁白，所以他们向我们表示感谢，”他说。 &lt;/p>; &lt;p id=&quot;iOXOOs&quot;>;在 &lt;em>;The Verge&lt;/em>; 的演示中，Toeman 表示用户可以编写或上传脚本给 Augie，然后使用预先录制的语音（人们需要录制一段他们说话的声音的简短片段）或从其库中选择一个。然后那个声音会用语气朗读剧本，严肃的、热情的、令人毛骨悚然的等等，可以根据视频的情绪进行调整。 &lt;/p>; &lt;p id=&quot;6uH5ud&quot;>;用户还可以从照片库中进行选择（Aug X 授权来自 Getty 的照片）或使用人工智能生成的图像添加到视频中。 &lt;/p>; &lt;p id=&quot;N4MEV2&quot;>;Toeman 设想营销团队可以扭转短视频的局面，而无需在录音室预订公司发言人的时间。&lt;/p>; &lt;p id=&quot;8fdZhT&quot;>;Augie 公开露面五月份的测试版。目前，每个使用 Augie 的人都可以使用语音克隆功能。托曼表示，最终，由于与合作伙伴一起运行语音克隆服务器的费用，它可能会限制视频长度和质量以及非付费用户的克隆语音数量。 &lt;/p>; &lt;p id=&quot;Lc0L3D&quot;>;语音克隆并不新鲜；三星&lt;a href=&quot;https://www.theverge.com/2023/2/22/23609915/samsung-ai-voice-clone-bixby-text-call-service-korean&quot;>;甚至允许人们使用人工智能语音&lt;/a>; 来响应呼叫，现在像 Aug X 这样的公司正在将该技术集成到功能更齐全的服务中。在一首以 AI 生成的说唱歌手声音为特色的 Deepfake Drake 歌曲疯传后，它帮助&lt;a href=&quot;https://www.theverge.com/2023/5/1/23703087/ai-drake-the-weeknd -music-copyright-legal-battle-right-of-publicity&quot;>;重新引发对版权和非法使用他人肖像的担忧&lt;/a>;。 &lt;/p>; &lt;p id=&quot;xFGcVn&quot;>;“我们已经预先考虑到了可能出现的问题，因此我们对于谁可以使用预先录制的语音进行克隆非常小心，”托曼说。 &lt;/p>; &lt;p id=&quot;4N4nQW&quot;>;他补充说，与更大的 Augie 库中的部分不同，录制的声音将仅对个人帐户可用。因此，同一组织中的另一个人必须在他们的 Augie 帐户上重新录制发言人的声音，以克隆他们的演讲。用户无法上传录音，平台只接受现场麦克风录制的声音。所以，不要把你前任的声音放在扬声器上，这样你就可以&lt;a href=&quot;https://www.tiktok.com/@miadio/video/7223745454608157998&quot;>;假装和一个非常乐于助人的朋友打电话&lt;/a>;是不行的和奥吉一起工作。 &lt;/p>; &lt;p id=&quot;C4iU7t&quot;>;该公司还与其语音克隆合作伙伴 ElevenLabs 合作，识别人工智能生成的语音和视频。 &lt;/p>; </content><link href="https://www.theverge.com/2023/8/10/23827676/ai-augx-voice-cloning-video-creator" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/10/23827676/ai-augx-voice-cloning-video-creator</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-10T13:39:07-04:00</published><updated> 2023-08-10T13:39:07-04:00</updated><title> FEC 可能会在 2024 年之前限制政治广告中的人工智能</title><content type="html">&lt;figure>; &lt;img alt=&quot;2023 年 7 月 23 日西班牙大选期间，一个人在马德里里奥斯罗萨斯投票站的投票亭投票。&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/ZT0-PR_JFgBa-Nr3jmi3DHqXBzQ=/0x0:4176x2784/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72532139/1548124131.0.jpg&quot; />; &lt;figcaption>;摄影：Oscar Del Pozo / 法新社，来自 Getty Images&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;a6cbeR&quot;>;经过数周的反复讨论，联邦选举委员会决定，也许，规范在政治广告中使用人工智能生成内容的规则。&lt;/p>; &lt;p id=&quot;hChxYG&quot;>;&lt;a href=&quot;https://www.fec.gov/updates/august-10-2023-open-在周四的一次公开会议上，FEC 投票决定开放公众意见征询书，启动了一个程序，该程序可能会导致管理竞选活动如何使用人工智能的新规则在今年年底前生效。该请愿书由倡导组织“公共公民”提交，呼吁该委员会利用其权力，制定规则，禁止候选人和政党使用人工智能歪曲对手，从而惩罚欺诈行为。 &lt;/p>; &lt;div class=&quot;c-float-left c-float-hang&quot;>;&lt;aside id=&quot;JAGVSb&quot;>;&lt;q>;“在选举广告中监管人工智能的深度假货和其他欺骗性使用变得更加紧迫日新月异”&lt;/q>;&lt;/aside>;&lt;/div>; &lt;p id=&quot;ZkKUrS&quot;>;“监管选举广告中人工智能的深度伪造和其他欺骗性使用的需求日渐变得更加紧迫，”Lisa公共公民执行副总裁吉尔伯特周四在一份声明中表示。 “联邦选举委员会决定进行公众意见征询期，这是一个令人鼓舞的迹象，表明人工智能对我们的民主构成的威胁最终可能会得到认真对待。”&lt;/p>; &lt;p id=&quot;uUBM9l&quot;>;共和党委员艾伦·迪克森 (Allen Dickerson) 反对请愿书它于今年夏天早些时候首次提交，但投票决定于周四开始评论期。尽管如此，迪克森质疑联邦选举委员会是否有必要的权力来执行所要求的规则，并建议公众公民和其他人应该要求联邦立法者首先采取行动。 &lt;/p>; &lt;p id=&quot;fpyozs&quot;>;“我怀疑，对于许多人来说，得知联邦选举委员会可能会监管对对手撒谎的候选人，这将是新闻。这是国会的选择，”迪克森在周四的会议上说道。 “联邦选举委员会一致要求其重新考虑这一选择，并授予我们更广泛的权力来惩罚竞选活动中的欺诈行为，但根据国会的权利，它选择忽略这一要求。”&lt;/p>; &lt;p id=&quot;qWIYAc&quot; >;在周四的投票之前，国会和白宫采取了一系列监管人工智能的行动。 5 月，OpenAI 首席执行官 Sam Altman &lt;a href=&quot;https://www.theverge.com/2023/5/16/23726119/congress-ai-hearing-sam-altman-openai&quot;>;在参议院司法委员会作证&lt; /a>;，表示立法者应迅速通过监管该行业的新规则，并特别要求政府制定许可计划。白宫还&lt;a href=&quot;https://www.theverge.com/2023/7/21/23803244/meta-google-openai-microsoft-artificial-intelligence-ai-white-house-commitments&quot;>;获得了一些顶级人工智能公司（例如 Altman 的公司）做出了一些自愿承诺&lt;/a>;，以负责任的方式开发该技术。 &lt;/p>; &lt;p id=&quot;8AduwX&quot;>;六月，参议院多数党领袖查克·舒默（纽约州民主党）提出了一项关于国会应如何监管该行业的计划，名为 &lt;a href=&quot;https://www.theverge .com/2023/6/21/23768257/ai-schumer-safe-innovation-framework-senate-openai-altman&quot;>;SAFE 创新框架&lt;/a>;。该计划要求立法者解决与人工智能相关的各种风险，从国家安全和失业到版权和错误信息。&lt;/p>; &lt;p id=&quot;WrQnJl&quot;>;与此同时，共和党全国委员会和永不退缩等政治团体罗恩·德桑蒂斯 (Ron DeSantis) 的超级政治行动委员会 (PAC) 已经开始使用这项技术。 4 月份，RNC &lt;a href=&quot;https://www.theverge.com/2023/4/25/23697328/biden-reelection-rnc-ai- generated-attack-ad-deepfake&quot;>;发布了人工智能生成的广告&lt;/a>;响应乔·拜登总统的选举公告，描绘了他赢得连任后的反乌托邦版本的未来。 &lt;a href=&quot;https://www.politico.com/news/2023/07/17/desantis-pac-ai- generated-trump-in-ad-00106695&quot;>;Never Back Down 使用 AI 进行模仿&lt;/a >; 前总统唐纳德·特朗普上个月在广告中的声音。 &lt;/p>; &lt;p id=&quot;l46boL&quot;>;这些攻击视频已迁移到规则同样宽松的社交平台。六月，德桑蒂斯竞选活动 &lt;a href=&quot;https://www.theverge.com/2023/6/8/23753626/deepfake-political-attack-ad-ron-desantis-donald-trump-anthony-fauci&quot;>;分享了一段视频，其中包含特朗普亲吻前白宫首席医疗顾问安东尼·福奇（Anthony Fauci）的虚假图像，他领导了美国应对 covid-19 的行动。&lt;/p>; &lt;p id=&quot;bEO20W&quot;>;民主党全国委员会和共和党全国委员会拒绝就他们过去是否会针对人工智能的使用发布内部规则发表评论。&lt;/p>; &lt;p id=&quot;u5mP7L&quot;>;虽然国会已明确表示有意针对该技术制定规则，但实际上很少有法案已经出台。众议员伊维特·克拉克 (D-NY) &lt;a href=&quot;https://www.theverge.com/2023/5/2/23708310/ai-artificial-intelligence-political-ads-election-rnc-biden&quot;>;第一个提出法案&lt;/a>;，要求竞选活动和政治团体披露何时在广告中包含人工智能生成的内容。明尼苏达州民主党参议员艾米·克洛布查 (Amy Klobuchar) 在参议院提出了克拉克措施的配套措施。&lt;/p>; &lt;p id=&quot;8bL1fY&quot;>;但是，尽管举行了一波听证会，国会在批准任何监管科技的规则方面却一拖再拖，立法以及他们近年来发布的激烈声明。随着 2024 年选举的临近，吉尔伯特和公众公民发出了请愿书，作为在竞选季全面开始之前制定一些规则的一种手段。 &lt;/p>; &lt;p id=&quot;dScPq5&quot;>;“这是解决方案的一部分，”吉尔伯特在周三接受 &lt;em>;The Verge&lt;/em>; 采访时说道。 “威尔还需要国会采取行动，全面禁止或要求在其他空间全面披露正在生成的竞选广告。”&lt;/p>; &lt;p id=&quot;i2DDW0&quot;>;周四投票后，克洛布查尔表示，她将提出一项新法案，以增强 FEC 对人工智能的权威。 &lt;/p>; &lt;p id=&quot;SfNlCB&quot;>;“人工智能越来越多地被用来生成误导性内容，这些内容可以用来针对任何政党的候选人，”Klobuchar 在给 &lt;em>;The Verge&lt;/em>; 的一份声明中表示。 “虽然今天的决定向前迈出了一步，但我们需要 FEC 现在就采取行动。我计划引入两党立法，明确联邦选举委员会处理此事的权力，无论他们是否已经拥有权力。”&lt;/p>; &lt;p id=&quot;iLQdIc&quot;>;一旦请愿书进入联邦登记册，公众将有 60 天的时间发表评论。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/10/23827399/ai-artificial-intelligence-political-ads-fec-desantis-rnc" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/10/23827399/ai-artificial-intelligence-political-ads-fec-desantis-rnc</id><author><name>马克纳·凯利</name></author></entry><entry><published>2023-08-10T12:18:25-04:00</published><updated> 2023-08-10T12:18:25-04:00</updated><title>新闻媒体要求人工智能训练数据制定新规则</title><content type="html">&lt;图>; &lt;img alt=&quot;美联社徽标&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/nRUZoOhqbE-tShe8BZqPq3xNwL8=/0x0:640x427/1310x873/cdn.vox-cdn.com/uploads/ chorus_image/image/72531843/AP_logo_640.0.jpg&quot; />; &lt;figcaption>;图片：AP&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;2y5sve&quot;>;多家媒体组织呼吁制定保护用于训练生成数据的版权的规则人工智能模型。 &lt;/p>; &lt;p id=&quot;sUODOD&quot;>;&lt;a href=&quot;https://drive.google.com/file/d/1jONWdRbwbS50hd1-x4fDvSyARJMCgRTY/view&quot;>;公开信&lt;/a>;敦促全球立法者考虑要求培训数据集透明并在使用数据进行培训之前征得权利持有者同意的法规。他们还要求允许媒体公司与人工智能模型运营商进行谈判，识别人工智能生成的内容，并要求人工智能公司消除其服务中的偏见和错误信息。 &lt;/p>; &lt;p id=&quot;D84Nuc&quot;>;这封信的签署者包括法新社、欧洲新闻图片社、欧洲出版商委员会、甘尼特、盖蒂图片社、国家新闻摄影师协会、国家作家联盟、新闻媒体联盟、美联社和作家协会。 &lt;/p>; &lt;p id=&quot;VySs17&quot;>;签名者表示，使用媒体内容训练的基金会模型传播信息“没有考虑、不向原始创作者支付报酬或归属于原始创作者。”&lt;/p>; &lt;p id=&quot;COP85S ”信中称，“此类做法破坏了媒体行业的核心商业模式，而这些模式以读者和收视率（例如订阅）、许可和广告为基础。” “除了违反版权法之外，由此产生的影响还大大减少了媒体多样性，损害了公司投资媒体报道的财务可行性，进一步减少了公众获取高质量和可信信息的机会。” &lt;/p>; &lt;p id=&quot;OuYiSa&quot;>;这封信是在&lt;a href=&quot;https://www.theverge.com/2023/7/19/23801282/google-ai-journalism-genesis-generative-news之后据报道，谷歌向《纽约时报》、《华盛顿邮报》和拥有《华尔街日报》的新闻集团展示了&lt;/a>;其生成式人工智能新闻写作工具 Genesis 。 &lt;a href=&quot;https://www.theverge.com/2023/1/19/23562966/cnet-ai-writing-stories-red-ventures-seo-marketing&quot;>;已采用生成式人工智能的其他新闻机构&lt;/ a>; 发现&lt;a href=&quot;https://www.theverge.com/2023/1/25/23571082/cnet-ai-writing-stories-errors- Corrections-red-ventures&quot;>;多个错误&lt;/a>;人工智能生成的文章。 &lt;/p>; &lt;p id=&quot;quDqV9&quot;>;新闻机构并不是唯一关心人工智能模型的机构&lt;a href=&quot;https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal -fair-use-training-data&quot;>;对受版权保护的材料进行培训&lt;/a>;——这种做法的法律地位尚未得到检验。参议院在多次听证会上讨论了这个问题，并提出了-midjourney-deviantart&quot;>;指控生成人工智能艺术平台&lt;/a>; Midjourney 和 Stable Diffusion 侵犯艺术家权利的诉讼正在法庭上审理。喜剧演员 Sarah Silverman 和两位作者起诉 OpenAI 涉嫌侵犯版权。&lt;/p>; &lt;p id=&quot;r6QlzE&quot;>;这封信的签名者指出，他们相信生成式 AI 可以为组织和公众带来重大利益，同时要求参与关于尊重版权的讨论媒体公司的权利。 &lt;/p>; &lt;p id=&quot;3HmOjR&quot;>;&lt;a href=&quot;https://www.reuters.com/business/media-telecom/news-firms-seek-transparency-collective-negotiation-over-content-use -by-ai-2023-08-09/&quot;>;&lt;em>;路透社&lt;/em>;报道&lt;/a>;，一些签署者已经达成协议，允许人工智能公司使用他们的材料进行培训。例如，美联社允许 OpenAI许可其部分档案并探索使用生成式人工智能进行新闻写作。 &lt;/p>; </content><link href="https://www.theverge.com/2023/8/10/23827316/news-transparency-copyright-generative-ai" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/10/23827316/news-transparency-copyright-generative-ai</id><author><name>艾米莉亚·大卫</name></author></entry><entry><published>2023-08-09T17:08:32-04:00</published><updated> 2023-08-09T17:08:32-04:00</updated><title> CNET 正在删除旧文章以试图提高其 Google 搜索排名</title><content type="html">&lt;图>; &lt;img alt=&quot;&quot; src=&quot;https://cdn.vox-cdn.com/thumbor/wqhqyy5Vpocvn9atTxDn9F2AorQ=/0x0:3000x2000/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/72529634 /gbeard_180612_2662_seo_death.0.jpg&quot; />; &lt;figcaption>;图片：Garret Beard / The Verge&lt;/figcaption>; &lt;/figure>; &lt;p id=&quot;Nn5HUY&quot;>;科技新闻媒体 &lt;em>;CNET&lt;/em>; 已删除数千条根据一份内部备忘录，该公司网站上的旧文章告诉员工，删除这些文章将提高其谷歌搜索排名。该消息&lt;a href=&quot;https://gizmodo.com/cnet-deletes-thousands-old-articles-google-search-seo-1850721475&quot;>;首先由&lt;em>;Gizmodo&lt;/em>;报道&lt;/a>; &lt;em>;.&lt;/em>;&lt;/p>; &lt;p id=&quot;UCpZLz&quot;>;&lt;em>;Gizmodo&lt;/em>; 报告称，自 7 月以来，数千篇文章已从 CNET 中删除。 &lt;/em>;在&lt;a href=&quot;https://www.documentcloud.org/documents/23903730-faq-on-cnet-content-pruning-aug-2023&quot;>;备忘录&lt;/a>;中，&lt;em>;CNET &lt;/em>;表示，所谓的内容修剪“向 Google 发出了一个信号，表明 CNET 是新鲜的、相关的，值得在搜索结果中比我们的竞争对手排名更高。”根据备忘录，计划“弃用”的故事将使用互联网档案馆的 Wayback Machine 进行存档，并至少提前 10 天向作者发出警报。&lt;/p>; &lt;p id=&quot;6DXHTV&quot;>;“从网站中删除内容这不是我们轻易做出的决定。我们的团队分析许多数据点，以确定 CNET 上是否存在当前无法为有意义的受众提供服务的页面。这些指标包括页面浏览量、反向链接配置文件以及自上次更新以来经过的时间量。”备忘录中写道。&lt;/p>; &lt;p id=&quot;IptTlH&quot;>;2021 年和 &lt;em>; 的 Wayback Machine 档案之间的比较CNET 自己的现场文章计数器显示，自 20 世纪 90 年代中期以来，每年都有数百（有时甚至数千）故事消失。无法获得 2022 年和 2023 年的数据。 Red Ventures 是一家私募股权支持的营销公司，拥有 &lt;em>;CNET&lt;/em>;，但没有立即回答有关已删除报道的确切数量的问题。&lt;/p>; &lt;p id=&quot;zWq2JA&quot; >;Red Ventures 对其一系列网点采用了严格的 SEO 策略，其中还包括 The Points Guy、Healthline&lt;em>; 和 Bankrate&lt;em>;。 &lt;/em>;一月份，&lt;em>;Futurism&lt;/em>;报道 &lt;em>;CNET&lt;/em>; 一直在悄悄地使用人工智能工具来撰写文章 - 这是一个广泛的 &lt;a href=&quot;https://www .theverge.com/2023/1/19/23562966/cnet-ai-writing-stories-red-ventures-seo-marketing&quot;>;人工智能驱动的 SEO 策略&lt;/a>;，其中使用生成式人工智能工具创建内容可以携带附属广告。在这一事件曝光并导致人工智能生成的故事出现错误后，Red Ventures 暂时暂停了内容并&lt;a href=&quot;https://www.theverge.com/2023/6/6/23750761/cnet-ai- generated -stories-policy-update&quot;>;彻底修改了人工智能政策&lt;/a>;。 &lt;em>;CNET &lt;/em>;工作人员&lt;a href=&quot;https://www.theverge.com/2023/5/16/23723959/cnet-union-red-ventures-tech-editorial-independence-ai-writing&quot; >;五月成立&lt;/a>;，理由是需要对生成式人工智能工具的使用方式以及网站如何通过其工作货币化进行更多控制。 &lt;em>;（披露：The Verge 的编辑人员还与美国东部作家协会建立了工会。）&lt;/em>;&lt;/p>; &lt;p id=&quot;f29cWW&quot;>;Red Ventures 和 &lt;em>;CNET &lt;/em>;通过指出 Google 搜索的排名算法来证明内容修剪的合理性，并表示该过程将“提高 SEO 排名并推动更有意义的用户参与”。正如 Gizmodo 指出的那样，删除大量档案本质上并不是一个好的 SEO 策略 - Google 曾&lt;a href=&quot;https://twitter.com/searchliaison/status/1689018769782476800&quot;>;说过&lt; /a>; 它的指导并不鼓励这种做法，尽管 SEO 专家告诉 &lt;em>;Gizmodo &lt;/em>;，如果小心操作，它可能对网站有益。 &lt;/p>; &lt;p id=&quot;Sv9mDO&quot;>;Red Ventures 似乎并没有被吓倒。根据备忘录，&lt;em>;CNET&lt;/em>; 将接受定期“内容修剪”，至少每年一次。&lt;/p>; </content><link href="https://www.theverge.com/2023/8/9/23826342/cnet-content-pruning-deleting-articles-google-seo" rel="alternate" type="text/html"/><id> https://www.theverge.com/2023/8/9/23826342/cnet-content-pruning-deleting-articles-google-seo</id><author><name>佐藤米娅</name></author></entry></feed>